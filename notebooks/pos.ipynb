{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pos.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdjyguoQUx32",
        "outputId": "5d8be07c-4cc0-4ff0-faa3-12026fcd7d44"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL_9sloYa1I5"
      },
      "source": [
        "DATA_FOLDER = '/content/drive/My Drive/Colab Notebooks/data/wsj'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ogry4OwbOs_"
      },
      "source": [
        "import os\n",
        "import re\n",
        "from collections import namedtuple\n",
        "\n",
        "TaggedWord = namedtuple('TaggedWord', ['word', 'tag'])\n",
        "START_TAG = '--s--'\n",
        "\n",
        "def preprocess_wsj(text):\n",
        "    corpus = []\n",
        "\n",
        "    for paragraph_text in text.split('=+'):\n",
        "        corpus.append(TaggedWord(word='', tag=START_TAG))\n",
        "        for line in paragraph_text.split('\\n'):\n",
        "            parts = line.split(' ')\n",
        "            for part in parts:\n",
        "                part = part.strip().strip(']').strip('[')\n",
        "                if len(part) > 0 and not part.startswith('='):\n",
        "                    subparts = part.split('/')\n",
        "                    if len(subparts) > 2:\n",
        "                        word, tag = subparts[0].strip('\\\\') + '/' + subparts[1], subparts[2]\n",
        "                    else:\n",
        "                        word, tag = subparts\n",
        "                    corpus.append(TaggedWord(word=word, tag=tag))\n",
        "    return corpus\n",
        "\n",
        "corpus = []\n",
        "for file in os.listdir(DATA_FOLDER):\n",
        "    if file.startswith('wsj'):\n",
        "        with open(DATA_FOLDER+f'/{file}') as f:\n",
        "            subcorpus = preprocess_wsj(f.read())\n",
        "            corpus.extend(subcorpus)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsasRswGetvK"
      },
      "source": [
        "split_num = int(len(corpus) * 0.8)\n",
        "training_corpus = corpus[:split_num]\n",
        "test_corpus = corpus[split_num:]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh_6a5eefsiH",
        "outputId": "8c987af4-d839-4092-9dee-f55ac765f8f5"
      },
      "source": [
        "training_corpus[:5]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TaggedWord(word='', tag='--s--'),\n",
              " TaggedWord(word='R.P.', tag='NNP'),\n",
              " TaggedWord(word='Scherer', tag='NNP'),\n",
              " TaggedWord(word='Corp.', tag='NNP'),\n",
              " TaggedWord(word='said', tag='VBD')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyO_EK7uhGYJ",
        "outputId": "930d8b76-77cb-494a-917d-9c344405b027"
      },
      "source": [
        "len(training_corpus)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75519"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl6Qqsygs8e0"
      },
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "def generate_vocab(corpus):\n",
        "    vocab = {}\n",
        "    index = 0\n",
        "\n",
        "    for (word, tag) in corpus:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = index\n",
        "            index += 1\n",
        "    \n",
        "    return vocab\n",
        "\n",
        "def create_dictionaries(corpus, vocab):\n",
        "    emission_counts = defaultdict(int)\n",
        "    transition_counts = defaultdict(int)\n",
        "    tag_counts = defaultdict(int)\n",
        "\n",
        "    prev_tag = '--s--'\n",
        "\n",
        "    for (word, tag) in corpus:\n",
        "        transition_counts[(prev_tag, tag)] += 1\n",
        "        emission_counts[(tag, word)] += 1\n",
        "        tag_counts[tag] += 1\n",
        "        prev_tag = tag\n",
        "\n",
        "    return emission_counts, transition_counts, tag_counts\n",
        "\n",
        "def create_transition_matrix(alpha, tag_counts, transition_counts):\n",
        "    tags = sorted(tag_counts.keys())\n",
        "    num_tags = len(tags)\n",
        "    transition_matrix = np.zeros((num_tags, num_tags))\n",
        "\n",
        "    for i in range(num_tags):\n",
        "        for j in range(num_tags):\n",
        "            trans_key = (tags[i], tags[j])\n",
        "            count = 0\n",
        "            if trans_key in transition_counts:\n",
        "                count = transition_counts[trans_key]\n",
        "            transition_matrix[i, j] = (count + alpha) / (tag_counts[tags[i]] + alpha * num_tags)\n",
        "    \n",
        "    return transition_matrix\n",
        "\n",
        "def create_emission_matrix(alpha, tag_counts, emission_counts, vocab):\n",
        "    tags = sorted(tag_counts.keys())\n",
        "    words = sorted(vocab.keys())\n",
        "    num_tags = len(tags)\n",
        "    num_words = len(words)\n",
        "    emission_matrix = np.zeros((num_tags, num_words))\n",
        "\n",
        "    for i in range(num_tags):\n",
        "        for j in range(num_words):\n",
        "            count = 0\n",
        "            emission_key = (tags[i], words[j])\n",
        "            if emission_key in emission_counts:\n",
        "                count = emission_counts[emission_key]\n",
        "            emission_matrix[i, j] = (count + alpha) / (tag_counts[tags[i]] + alpha * num_words)\n",
        "    \n",
        "    return emission_matrix"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Iujv4SyzKJ5"
      },
      "source": [
        "vocab = generate_vocab(corpus)\n",
        "emission_counts, transition_counts, tag_counts = create_dictionaries(training_corpus, vocab)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCWAZ2tlzl8-"
      },
      "source": [
        "transition_matrix = create_transition_matrix(0.001, tag_counts, transition_counts)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_UJSJ8m1oyN",
        "outputId": "6deeeb18-f30a-4e15-9222-3ea98666886f"
      },
      "source": [
        "transition_matrix"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.11895778e-05, 7.11895778e-05, 7.11895778e-05, ...,\n",
              "        7.11895778e-05, 7.11895778e-05, 7.11895778e-05],\n",
              "       [1.74810811e-06, 1.74810811e-06, 1.74810811e-06, ...,\n",
              "        1.74810811e-06, 1.74810811e-06, 1.74810811e-06],\n",
              "       [1.65824554e-06, 1.65824554e-06, 6.63464042e-03, ...,\n",
              "        1.65990379e-03, 3.31814933e-03, 1.32676226e-02],\n",
              "       ...,\n",
              "       [9.05223138e-05, 9.05223138e-05, 9.05223138e-05, ...,\n",
              "        9.05223138e-05, 9.05223138e-05, 9.05223138e-05],\n",
              "       [6.70929304e-06, 6.70929304e-06, 6.70929304e-06, ...,\n",
              "        6.70929304e-06, 6.70929304e-06, 6.71600233e-03],\n",
              "       [1.65824554e-06, 1.65824554e-06, 1.65824554e-06, ...,\n",
              "        1.65824554e-06, 9.95113150e-03, 1.65824554e-06]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpvsYMLh4oo1"
      },
      "source": [
        "emission_matrix = create_emission_matrix(0.001, tag_counts, emission_counts, vocab)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmYBt686ArQ-",
        "outputId": "3a77faa7-9d30-40ca-895b-7e48d055cd24"
      },
      "source": [
        "emission_matrix"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.84704162e-05, 3.84704162e-05, 5.38624298e-01, ...,\n",
              "        3.84704162e-05, 3.84704162e-05, 3.84704162e-05],\n",
              "       [1.71234636e-06, 1.71234636e-06, 1.71234636e-06, ...,\n",
              "        1.71234636e-06, 1.71234636e-06, 1.71234636e-06],\n",
              "       [1.62603212e-06, 1.62603212e-06, 1.62603212e-06, ...,\n",
              "        1.62603212e-06, 1.62603212e-06, 1.62603212e-06],\n",
              "       ...,\n",
              "       [4.34896060e-05, 4.34896060e-05, 4.34896060e-05, ...,\n",
              "        4.34896060e-05, 4.34896060e-05, 4.34896060e-05],\n",
              "       [6.21141161e-06, 6.21141161e-06, 6.21141161e-06, ...,\n",
              "        6.21141161e-06, 6.21141161e-06, 6.21141161e-06],\n",
              "       [1.62603212e-06, 1.62603212e-06, 1.62603212e-06, ...,\n",
              "        1.62603212e-06, 1.62603212e-06, 1.62603212e-06]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anKCSJTvOHuU"
      },
      "source": [
        "import math\n",
        "\n",
        "def initialize(states, tag_counts, A, B, corpus, vocab):\n",
        "    '''\n",
        "    Input: \n",
        "        states: a list of all possible parts-of-speech\n",
        "        tag_counts: a dictionary mapping each tag to its respective count\n",
        "        A: Transition Matrix of dimension (num_tags, num_tags)\n",
        "        B: Emission Matrix of dimension (num_tags, len(vocab))\n",
        "        corpus: a sequence of words whose POS is to be identified in a list \n",
        "        vocab: a dictionary where keys are words in vocabulary and value is an index\n",
        "    Output:\n",
        "        best_probs: matrix of dimension (num_tags, len(corpus)) of floats\n",
        "        best_paths: matrix of dimension (num_tags, len(corpus)) of integers\n",
        "    '''\n",
        "    # Get the total number of unique POS tags\n",
        "    num_tags = len(tag_counts)\n",
        "    \n",
        "    # Initialize best_probs matrix \n",
        "    # POS tags in the rows, number of words in the corpus as the columns\n",
        "    best_probs = np.zeros((num_tags, len(corpus)))\n",
        "    \n",
        "    # Initialize best_paths matrix\n",
        "    # POS tags in the rows, number of words in the corpus as columns\n",
        "    best_paths = np.zeros((num_tags, len(corpus)), dtype=int)\n",
        "    \n",
        "    # Define the start token\n",
        "    s_idx = states.index(\"--s--\")\n",
        "    \n",
        "    # Go through each of the POS tags\n",
        "    for i in range(num_tags):\n",
        "        \n",
        "        # Handle the special case when the transition from start token to POS tag i is zero\n",
        "        if A[s_idx, i] == 0:\n",
        "            # Initialize best_probs at POS tag 'i', column 0, to negative infinity\n",
        "            best_probs[i,0] = float('-inf')\n",
        "        \n",
        "        # For all other cases when transition from start token to POS tag i is non-zero:\n",
        "        else:\n",
        "            # Initialize best_probs at POS tag 'i', column 0\n",
        "            # Check the formula in the instructions above\n",
        "            best_probs[i,0] = math.log(A[s_idx, i]) + math.log(B[i, vocab[corpus[0][0]]])\n",
        "                        \n",
        "    return best_probs, best_paths\n",
        "\n",
        "def viterbi_forward(A, B, test_corpus, best_probs, best_paths, vocab):\n",
        "    '''\n",
        "    Input: \n",
        "        A, B: The transition and emission matrices respectively\n",
        "        test_corpus: a list containing a preprocessed corpus\n",
        "        best_probs: an initilized matrix of dimension (num_tags, len(corpus))\n",
        "        best_paths: an initilized matrix of dimension (num_tags, len(corpus))\n",
        "        vocab: a dictionary where keys are words in vocabulary and value is an index \n",
        "    Output: \n",
        "        best_probs: a completed matrix of dimension (num_tags, len(corpus))\n",
        "        best_paths: a completed matrix of dimension (num_tags, len(corpus))\n",
        "    '''\n",
        "    # Get the number of unique POS tags (which is the num of rows in best_probs)\n",
        "    num_tags = best_probs.shape[0]\n",
        "    \n",
        "    # Go through every word in the corpus starting from word 1\n",
        "    # Recall that word 0 was initialized in `initialize()`\n",
        "    for i in range(1, len(test_corpus)): \n",
        "        \n",
        "        # Print number of words processed, every 5000 words\n",
        "        if i % 5000 == 0:\n",
        "            print(\"Words processed: {:>8}\".format(i))\n",
        "            \n",
        "        # For each unique POS tag that the current word can be\n",
        "        for j in range(num_tags):\n",
        "            \n",
        "            # Initialize best_prob for word i to negative infinity\n",
        "            best_prob_i = float('-inf')\n",
        "            \n",
        "            # Initialize best_path for current word i to None\n",
        "            best_path_i = None\n",
        "\n",
        "            # For each POS tag that the previous word can be:\n",
        "            for k in range(num_tags):\n",
        "            \n",
        "                # Calculate the probability = \n",
        "                # best probs of POS tag k, previous word i-1 + \n",
        "                # log(prob of transition from POS k to POS j) + \n",
        "                # log(prob that emission of POS j is word i)\n",
        "                prob = best_probs[k, i-1] + math.log(A[k, j]) + math.log(B[j, vocab[test_corpus[i][0]]])\n",
        "\n",
        "                # check if this path's probability is greater than\n",
        "                # the best probability up to and before this point\n",
        "                if prob > best_prob_i: # complete this line\n",
        "                    \n",
        "                    # Keep track of the best probability\n",
        "                    best_prob_i = prob\n",
        "                    \n",
        "                    # keep track of the POS tag of the previous word\n",
        "                    # that is part of the best path.  \n",
        "                    # Save the index (integer) associated with \n",
        "                    # that previous word's POS tag\n",
        "                    best_path_i = k\n",
        "\n",
        "            # Save the best probability for the \n",
        "            # given current word's POS tag\n",
        "            # and the position of the current word inside the corpus\n",
        "            best_probs[j,i] = best_prob_i\n",
        "            \n",
        "            # Save the unique integer ID of the previous POS tag\n",
        "            # into best_paths matrix, for the POS tag of the current word\n",
        "            # and the position of the current word inside the corpus.\n",
        "            best_paths[j,i] = best_path_i\n",
        "\n",
        "    return best_probs, best_paths\n",
        "\n",
        "def viterbi_backward(best_probs, best_paths, corpus, states):\n",
        "    '''\n",
        "    This function returns the best path.\n",
        "    \n",
        "    '''\n",
        "    # Get the number of words in the corpus\n",
        "    # which is also the number of columns in best_probs, best_paths\n",
        "    m = best_paths.shape[1] \n",
        "    \n",
        "    # Initialize array z, same length as the corpus\n",
        "    z = [None] * m\n",
        "    \n",
        "    # Get the number of unique POS tags\n",
        "    num_tags = best_probs.shape[0]\n",
        "    \n",
        "    # Initialize the best probability for the last word\n",
        "    best_prob_for_last_word = float('-inf')\n",
        "    \n",
        "    # Initialize pred array, same length as corpus\n",
        "    pred = [None] * m\n",
        "    \n",
        "    # Go through each POS tag for the last word (last column of best_probs)\n",
        "    # in order to find the row (POS tag integer ID) \n",
        "    # with highest probability for the last word\n",
        "    for k in range(num_tags):\n",
        "\n",
        "        # If the probability of POS tag at row k \n",
        "        # is better than the previously best probability for the last word:\n",
        "        if best_probs[k, m-1] > best_prob_for_last_word: # complete this line\n",
        "            \n",
        "            # Store the new best probability for the lsat word\n",
        "            best_prob_for_last_word = best_probs[k, m-1]\n",
        "    \n",
        "            # Store the unique integer ID of the POS tag\n",
        "            # which is also the row number in best_probs\n",
        "            z[m - 1] = k\n",
        "            \n",
        "    # Convert the last word's predicted POS tag\n",
        "    # from its unique integer ID into the string representation\n",
        "    # using the 'states' dictionary\n",
        "    # store this in the 'pred' array for the last word\n",
        "    pred[m - 1] = states[z[m-1]]\n",
        "    \n",
        "    # Find the best POS tags by walking backward through the best_paths\n",
        "    # From the last word in the corpus to the 0th word in the corpus\n",
        "    for i in range(m-1, 0, -1):\n",
        "        \n",
        "        # Retrieve the unique integer ID of\n",
        "        # the POS tag for the word at position 'i' in the corpus\n",
        "        pos_tag_for_word_i = z[i]\n",
        "        \n",
        "        # In best_paths, go to the row representing the POS tag of word i\n",
        "        # and the column representing the word's position in the corpus\n",
        "        # to retrieve the predicted POS for the word at position i-1 in the corpus\n",
        "        z[i - 1] = best_paths[pos_tag_for_word_i,i]\n",
        "        \n",
        "        # Get the previous word's POS tag in string form\n",
        "        # Use the 'states' dictionary, \n",
        "        # where the key is the unique integer ID of the POS tag,\n",
        "        # and the value is the string representation of that POS tag\n",
        "        pred[i - 1] = states[z[i-1]]\n",
        "        \n",
        "    return pred\n",
        "\n",
        "def compute_accuracy(pred, y):\n",
        "    '''\n",
        "    Input: \n",
        "        pred: a list of the predicted parts-of-speech \n",
        "        y: a list of word, tag tuples\n",
        "    Output: \n",
        "        \n",
        "    '''\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    # Zip together the prediction and the labels\n",
        "    for prediction, (word, tag) in zip(pred, y):\n",
        "        \n",
        "        # Check if the POS tag label matches the prediction\n",
        "        if tag == prediction:\n",
        "            \n",
        "            # count the number of times that the prediction\n",
        "            # and label match\n",
        "            num_correct += 1\n",
        "            \n",
        "        # keep track of the total number of examples (that have valid labels)\n",
        "        total += 1\n",
        "        \n",
        "    return num_correct/total"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgfoII43b5xw"
      },
      "source": [
        "states = sorted(tag_counts.keys())\n",
        "best_probs, best_paths = initialize(states, tag_counts, transition_matrix, emission_matrix, corpus, vocab)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_2jM1hicNjN",
        "outputId": "73b33b6d-79ac-4979-92f8-2019e2c37a38"
      },
      "source": [
        "viterbi_forward(transition_matrix, emission_matrix, test_corpus, best_probs, best_paths, vocab)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words processed:     5000\n",
            "Words processed:    10000\n",
            "Words processed:    15000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-22.12353354, -27.24675713, -40.93673904, ...,   0.        ,\n",
              "           0.        ,   0.        ],\n",
              "        [-25.23555851, -30.3587821 , -37.0786291 , ...,   0.        ,\n",
              "           0.        ,   0.        ],\n",
              "        [-25.28728031, -30.4105039 , -35.3650472 , ...,   0.        ,\n",
              "           0.        ,   0.        ],\n",
              "        ...,\n",
              "        [-22.00090111, -27.1241247 , -34.56311644, ...,   0.        ,\n",
              "           0.        ,   0.        ],\n",
              "        [-17.03828012, -22.16150371, -34.63787101, ...,   0.        ,\n",
              "           0.        ,   0.        ],\n",
              "        [-17.68587798, -22.80910157, -36.34580702, ...,   0.        ,\n",
              "           0.        ,   0.        ]]), array([[ 0,  6, 14, ...,  0,  0,  0],\n",
              "        [ 0,  6,  3, ...,  0,  0,  0],\n",
              "        [ 0,  6, 23, ...,  0,  0,  0],\n",
              "        ...,\n",
              "        [ 0,  6, 23, ...,  0,  0,  0],\n",
              "        [ 0,  6, 23, ...,  0,  0,  0],\n",
              "        [ 0,  6, 23, ...,  0,  0,  0]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsFpSUr7d50u"
      },
      "source": [
        "pred = viterbi_backward(best_probs, best_paths, test_corpus, states)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1sL3qT6i42p"
      },
      "source": [
        "compute_accuracy(pred, test_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWKUWIICjwVj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}