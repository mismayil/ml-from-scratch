{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /Users/mismayil/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('reuters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "text = reuters.raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1274933"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asian',\n",
       " 'exporters',\n",
       " 'fear',\n",
       " 'damage',\n",
       " 'from',\n",
       " 'rift',\n",
       " 'mounting',\n",
       " 'trade',\n",
       " 'friction',\n",
       " 'between',\n",
       " 'the',\n",
       " 'and',\n",
       " 'japan',\n",
       " 'has',\n",
       " 'raised',\n",
       " 'fears',\n",
       " 'among',\n",
       " 'many',\n",
       " 'of',\n",
       " 'asia',\n",
       " 'exporting',\n",
       " 'nations',\n",
       " 'that',\n",
       " 'the',\n",
       " 'row',\n",
       " 'could',\n",
       " 'inflict',\n",
       " 'economic',\n",
       " 'damage',\n",
       " 'businessmen',\n",
       " 'and',\n",
       " 'officials',\n",
       " 'said',\n",
       " 'they',\n",
       " 'told',\n",
       " 'reuter',\n",
       " 'correspondents',\n",
       " 'in',\n",
       " 'asian',\n",
       " 'capitals',\n",
       " 'a',\n",
       " 'move',\n",
       " 'against',\n",
       " 'japan',\n",
       " 'might',\n",
       " 'boost',\n",
       " 'protectionist',\n",
       " 'sentiment',\n",
       " 'in',\n",
       " 'the']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vocab(tokens):\n",
    "    vocab = dict()\n",
    "    \n",
    "    for i, token in enumerate(set(tokens)):\n",
    "        vocab[token] = i\n",
    "    \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = generate_vocab(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27952"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def one_hot_encode(token, vocab):\n",
    "    vector = np.zeros(len(vocab))\n",
    "    vector[vocab[token]] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_data(tokens, vocab, context_size=2):\n",
    "    V = len(vocab)\n",
    "    X, y = [], []\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        context = tokens[i-context_size:i] + tokens[i+1:i+context_size+1]\n",
    "        context_vector = np.zeros(V)\n",
    "        \n",
    "        for word in context:\n",
    "            context_vector += np.array(one_hot_encode(word, vocab))\n",
    "        context_vector = context_vector / len(context)\n",
    "        center_vector = one_hot_encode(tokens[i], vocab)\n",
    "        \n",
    "        X.append(context_vector)\n",
    "        y.append(center_vector)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def generate_batch_data(tokens, vocab, context_size=2, batch_size=128):\n",
    "    batches = 0\n",
    "\n",
    "    while True:\n",
    "        batch_tokens = tokens[batches*batch_size:(batches+1)*batch_size]\n",
    "        if batch_tokens:\n",
    "            yield generate_train_data(batch_tokens, vocab, context_size)\n",
    "            batches += 1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['I', 'think', 'therefore', 'I', 'am']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = generate_vocab(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'think': 0, 'am': 1, 'therefore': 2, 'I': 3}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encode('am', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = generate_train_data(tokens, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.        , 0.25      , 0.33333333, 0.        ],\n",
       "       [0.        , 0.        , 0.25      , 0.33333333, 0.        ],\n",
       "       [0.5       , 0.5       , 0.        , 0.33333333, 0.5       ],\n",
       "       [0.        , 0.5       , 0.5       , 0.        , 0.5       ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def backward(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Linear(Layer):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.weights = np.random.rand(in_dim, out_dim)\n",
    "        self.bias = np.random.rand(1, out_dim)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.input = X\n",
    "        self.output = np.dot(self.input, self.weights) + self.bias\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, out_error, learning_rate=0.05):\n",
    "        in_error = np.dot(out_error, self.weights.T)\n",
    "        weights_error = np.dot(self.input.T, out_error)\n",
    "        bias_error = out_error\n",
    "        \n",
    "        self.weights = self.weights - learning_rate * weights_error\n",
    "        self.bias = self.bias - learning_rate * bias_error\n",
    "        \n",
    "        return in_error\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return x > 0\n",
    "\n",
    "def softmax(x, axis=1):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=axis, keepdims=True)\n",
    "\n",
    "def cross_entropy(x, target, axis=1):\n",
    "    return (-1/target.shape[0]) * np.sum(target * np.log(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return 1-np.tanh(x)**2\n",
    "\n",
    "class Activation(Layer):\n",
    "    def __init__(self, activation):\n",
    "        activation_map = {\n",
    "            'relu': {\n",
    "                'func': relu,\n",
    "                'derivative': relu_derivative\n",
    "            },\n",
    "            'tanh': {\n",
    "                'func': tanh,\n",
    "                'derivative': tanh_derivative\n",
    "            }\n",
    "        }\n",
    "        self.activation = activation_map[activation]['func']\n",
    "        self.derivative = activation_map[activation]['derivative']\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.input = X\n",
    "        self.output = self.activation(self.input)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, out_error, learning_rate):\n",
    "        return self.derivative(self.input) * out_error\n",
    "\n",
    "class Loss(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.target = None\n",
    "\n",
    "class CrossEntropyLoss(Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.softmax_out = None\n",
    "\n",
    "    def forward(self, X, target):\n",
    "        self.input = X\n",
    "        self.target = target\n",
    "        self.softmax_out = softmax(self.input)\n",
    "        self.output = cross_entropy(self.softmax_out, self.target)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self):\n",
    "        return (1/self.target.shape[0])*(self.softmax_out - self.target)\n",
    "\n",
    "class MSELoss(Loss):\n",
    "    def forward(self, X, target):\n",
    "        self.input = X\n",
    "        self.target = target\n",
    "        self.output = np.mean(np.power(target-X, 2))\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self):\n",
    "        return (2 * (self.input-self.target)) / self.target.shape[0]\n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "    \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def set_loss(self, loss):\n",
    "        self.loss = loss\n",
    "    \n",
    "    def train(self, X, y, epochs=10, learning_rate=0.05):\n",
    "        for i in range(epochs):\n",
    "            predictions = self.predict(X)\n",
    "            \n",
    "            loss = self.loss()\n",
    "            cost = loss.forward(predictions, y)\n",
    "            \n",
    "            error = loss.backward()\n",
    "            \n",
    "            for layer in reversed(self.layers):\n",
    "                error = layer.backward(error, learning_rate)\n",
    "            \n",
    "            print(f'epoch={i}, loss={cost}')\n",
    "    \n",
    "    def predict(self, X):\n",
    "        output = X\n",
    "        for layer in self.layers:\n",
    "            output = layer.forward(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, loss=0.3896520997009981\n",
      "epoch=1, loss=0.38480037198559675\n",
      "epoch=2, loss=0.37967755673105086\n",
      "epoch=3, loss=0.37427427407523217\n",
      "epoch=4, loss=0.36858270723852515\n",
      "epoch=5, loss=0.36259706916053525\n",
      "epoch=6, loss=0.3563141026964657\n",
      "epoch=7, loss=0.3497335923181594\n",
      "epoch=8, loss=0.3428588552654982\n",
      "epoch=9, loss=0.3356971694116138\n",
      "epoch=10, loss=0.3282600850717787\n",
      "epoch=11, loss=0.3205635605485538\n",
      "epoch=12, loss=0.31262785882532995\n",
      "epoch=13, loss=0.30447714815092775\n",
      "epoch=14, loss=0.29613876458234023\n",
      "epoch=15, loss=0.2876421210272675\n",
      "epoch=16, loss=0.27901728421238436\n",
      "epoch=17, loss=0.2702932851665606\n",
      "epoch=18, loss=0.2614962748407633\n",
      "epoch=19, loss=0.2526476776306834\n",
      "epoch=20, loss=0.24376252539815588\n",
      "epoch=21, loss=0.23484816897634125\n",
      "epoch=22, loss=0.2259035627448097\n",
      "epoch=23, loss=0.2169193042632268\n",
      "epoch=24, loss=0.20787859094175595\n",
      "epoch=25, loss=0.1987592335891994\n",
      "epoch=26, loss=0.18953684005524285\n",
      "epoch=27, loss=0.18018923652494723\n",
      "epoch=28, loss=0.17070209860233893\n",
      "epoch=29, loss=0.16107557346271545\n",
      "epoch=30, loss=0.15133134057592257\n",
      "epoch=31, loss=0.1415190665530709\n",
      "epoch=32, loss=0.1317206359632037\n",
      "epoch=33, loss=0.12205011931066342\n",
      "epoch=34, loss=0.11264757471678971\n",
      "epoch=35, loss=0.10366589057830727\n",
      "epoch=36, loss=0.09525203518190481\n",
      "epoch=37, loss=0.08752661996265927\n",
      "epoch=38, loss=0.0805672408716726\n",
      "epoch=39, loss=0.07440037807529715\n",
      "epoch=40, loss=0.06900368046787626\n",
      "epoch=41, loss=0.06431675565747563\n",
      "epoch=42, loss=0.060256131519718606\n",
      "epoch=43, loss=0.05672984753170342\n",
      "epoch=44, loss=0.05364866585157333\n",
      "epoch=45, loss=0.05093290398683814\n",
      "epoch=46, loss=0.04851538658900852\n",
      "epoch=47, loss=0.04634168100962034\n",
      "epoch=48, loss=0.04436880637316902\n",
      "epoch=49, loss=0.04256331986920801\n",
      "epoch=50, loss=0.04089934004939932\n",
      "epoch=51, loss=0.0393567892687363\n",
      "epoch=52, loss=0.03791995621217992\n",
      "epoch=53, loss=0.036576379934489686\n",
      "epoch=54, loss=0.03531601234763866\n",
      "epoch=55, loss=0.03413060320361304\n",
      "epoch=56, loss=0.03301325426411744\n",
      "epoch=57, loss=0.03195809804514416\n",
      "epoch=58, loss=0.03096006637504889\n",
      "epoch=59, loss=0.030014722851990833\n",
      "epoch=60, loss=0.02911814043256826\n",
      "epoch=61, loss=0.028266810817297157\n",
      "epoch=62, loss=0.027457576276513115\n",
      "epoch=63, loss=0.0266875774002265\n",
      "epoch=64, loss=0.025954212249072448\n",
      "epoch=65, loss=0.025255103767445684\n",
      "epoch=66, loss=0.02458807327396463\n",
      "epoch=67, loss=0.023951118499696094\n",
      "epoch=68, loss=0.02334239509422919\n",
      "epoch=69, loss=0.022760200828697237\n",
      "epoch=70, loss=0.022202961937985204\n",
      "epoch=71, loss=0.021669221192236805\n",
      "epoch=72, loss=0.02115762739118727\n",
      "epoch=73, loss=0.020666926047896484\n",
      "epoch=74, loss=0.020195951080683627\n",
      "epoch=75, loss=0.019743617369928548\n",
      "epoch=76, loss=0.019308914064289032\n",
      "epoch=77, loss=0.018890898541769074\n",
      "epoch=78, loss=0.018488690946997836\n",
      "epoch=79, loss=0.018101469238441373\n",
      "epoch=80, loss=0.01772846468904034\n",
      "epoch=81, loss=0.017368957791620666\n",
      "epoch=82, loss=0.01702227452683888\n",
      "epoch=83, loss=0.016687782956737986\n",
      "epoch=84, loss=0.016364890111448396\n",
      "epoch=85, loss=0.01605303914035138\n",
      "epoch=86, loss=0.01575170670226289\n",
      "epoch=87, loss=0.015460400571992732\n",
      "epoch=88, loss=0.015178657443066517\n",
      "epoch=89, loss=0.014906040908523635\n",
      "epoch=90, loss=0.01464213960357392\n",
      "epoch=91, loss=0.01438656549554191\n",
      "epoch=92, loss=0.014138952307988168\n",
      "epoch=93, loss=0.01389895406719066\n",
      "epoch=94, loss=0.013666243760322787\n",
      "epoch=95, loss=0.013440512095692218\n",
      "epoch=96, loss=0.013221466356323078\n",
      "epoch=97, loss=0.013008829338987329\n",
      "epoch=98, loss=0.012802338371527434\n",
      "epoch=99, loss=0.012601744401974996\n",
      "epoch=100, loss=0.012406811153565019\n",
      "epoch=101, loss=0.012217314340280474\n",
      "epoch=102, loss=0.012033040938045237\n",
      "epoch=103, loss=0.011853788507117591\n",
      "epoch=104, loss=0.011679364561630249\n",
      "epoch=105, loss=0.011509585982577416\n",
      "epoch=106, loss=0.011344278470870856\n",
      "epoch=107, loss=0.011183276037377368\n",
      "epoch=108, loss=0.01102642052711379\n",
      "epoch=109, loss=0.01087356117501463\n",
      "epoch=110, loss=0.010724554190904045\n",
      "epoch=111, loss=0.010579262371501075\n",
      "epoch=112, loss=0.010437554737466138\n",
      "epoch=113, loss=0.010299306193659588\n",
      "epoch=114, loss=0.010164397210931857\n",
      "epoch=115, loss=0.010032713527899445\n",
      "epoch=116, loss=0.009904145871284853\n",
      "epoch=117, loss=0.0097785896935105\n",
      "epoch=118, loss=0.009655944926340143\n",
      "epoch=119, loss=0.009536115749454604\n",
      "epoch=120, loss=0.009419010372934924\n",
      "epoch=121, loss=0.009304540832704615\n",
      "epoch=122, loss=0.009192622798054726\n",
      "epoch=123, loss=0.00908317539044134\n",
      "epoch=124, loss=0.00897612101280602\n",
      "epoch=125, loss=0.008871385188724849\n",
      "epoch=126, loss=0.008768896410743174\n",
      "epoch=127, loss=0.008668585997299982\n",
      "epoch=128, loss=0.008570387957688769\n",
      "epoch=129, loss=0.008474238864541937\n",
      "epoch=130, loss=0.008380077733361878\n",
      "epoch=131, loss=0.008287845908656012\n",
      "epoch=132, loss=0.008197486956263773\n",
      "epoch=133, loss=0.008108946561492615\n",
      "epoch=134, loss=0.008022172432706217\n",
      "epoch=135, loss=0.007937114210032823\n",
      "epoch=136, loss=0.00785372337888409\n",
      "epoch=137, loss=0.007771953187995855\n",
      "epoch=138, loss=0.00769175857172159\n",
      "epoch=139, loss=0.007613096076326963\n",
      "epoch=140, loss=0.007535923790051237\n",
      "epoch=141, loss=0.007460201276715601\n",
      "epoch=142, loss=0.007385889512673947\n",
      "epoch=143, loss=0.007312950826913895\n",
      "epoch=144, loss=0.007241348844128882\n",
      "epoch=145, loss=0.007171048430593125\n",
      "epoch=146, loss=0.007102015642682158\n",
      "epoch=147, loss=0.0070342176778914155\n",
      "epoch=148, loss=0.006967622828214676\n",
      "epoch=149, loss=0.006902200435752408\n",
      "epoch=150, loss=0.006837920850428625\n",
      "epoch=151, loss=0.006774755389701689\n",
      "epoch=152, loss=0.006712676300161914\n",
      "epoch=153, loss=0.006651656720914877\n",
      "epoch=154, loss=0.006591670648655934\n",
      "epoch=155, loss=0.006532692904346389\n",
      "epoch=156, loss=0.006474699101407712\n",
      "epoch=157, loss=0.00641766561535463\n",
      "epoch=158, loss=0.0063615695547927596\n",
      "epoch=159, loss=0.006306388733710822\n",
      "epoch=160, loss=0.006252101645001242\n",
      "epoch=161, loss=0.006198687435146934\n",
      "epoch=162, loss=0.006146125880015712\n",
      "epoch=163, loss=0.006094397361706593\n",
      "epoch=164, loss=0.0060434828463960975\n",
      "epoch=165, loss=0.005993363863134836\n",
      "epoch=166, loss=0.005944022483547959\n",
      "epoch=167, loss=0.005895441302395281\n",
      "epoch=168, loss=0.005847603418949515\n",
      "epoch=169, loss=0.00580049241915314\n",
      "epoch=170, loss=0.005754092358516656\n",
      "epoch=171, loss=0.00570838774572305\n",
      "epoch=172, loss=0.00566336352690497\n",
      "epoch=173, loss=0.005619005070563099\n",
      "epoch=174, loss=0.005575298153095743\n",
      "epoch=175, loss=0.005532228944911277\n",
      "epoch=176, loss=0.005489783997096555\n",
      "epoch=177, loss=0.005447950228615819\n",
      "epoch=178, loss=0.005406714914015897\n",
      "epoch=179, loss=0.0053660656716147115\n",
      "epoch=180, loss=0.0053259904521514466\n",
      "epoch=181, loss=0.005286477527877547\n",
      "epoch=182, loss=0.0052475154820690205\n",
      "epoch=183, loss=0.00520909319894143\n",
      "epoch=184, loss=0.005171199853949674\n",
      "epoch=185, loss=0.005133824904455928\n",
      "epoch=186, loss=0.005096958080749638\n",
      "epoch=187, loss=0.005060589377404273\n",
      "epoch=188, loss=0.005024709044956453\n",
      "epoch=189, loss=0.0049893075818936376\n",
      "epoch=190, loss=0.004954375726937208\n",
      "epoch=191, loss=0.00491990445160847\n",
      "epoch=192, loss=0.004885884953065708\n",
      "epoch=193, loss=0.004852308647200901\n",
      "epoch=194, loss=0.004819167161985327\n",
      "epoch=195, loss=0.0047864523310537505\n",
      "epoch=196, loss=0.0047541561875173825\n",
      "epoch=197, loss=0.004722270957996216\n",
      "epoch=198, loss=0.004690789056861862\n",
      "epoch=199, loss=0.004659703080682324\n",
      "epoch=200, loss=0.004629005802860543\n",
      "epoch=201, loss=0.004598690168459076\n",
      "epoch=202, loss=0.004568749289203317\n",
      "epoch=203, loss=0.004539176438656313\n",
      "epoch=204, loss=0.004509965047558384\n",
      "epoch=205, loss=0.004481108699325008\n",
      "epoch=206, loss=0.0044526011256968995\n",
      "epoch=207, loss=0.004424436202536279\n",
      "epoch=208, loss=0.004396607945763791\n",
      "epoch=209, loss=0.004369110507430517\n",
      "epoch=210, loss=0.004341938171920082\n",
      "epoch=211, loss=0.004315085352275756\n",
      "epoch=212, loss=0.004288546586647985\n",
      "epoch=213, loss=0.004262316534857605\n",
      "epoch=214, loss=0.004236389975070594\n",
      "epoch=215, loss=0.004210761800580129\n",
      "epoch=216, loss=0.004185427016691945\n",
      "epoch=217, loss=0.0041603807377091784\n",
      "epoch=218, loss=0.0041356181840131205\n",
      "epoch=219, loss=0.00411113467923628\n",
      "epoch=220, loss=0.0040869256475244385\n",
      "epoch=221, loss=0.004062986610884499\n",
      "epoch=222, loss=0.004039313186614941\n",
      "epoch=223, loss=0.004015901084816071\n",
      "epoch=224, loss=0.003992746105977095\n",
      "epoch=225, loss=0.003969844138637335\n",
      "epoch=226, loss=0.003947191157118915\n",
      "epoch=227, loss=0.0039247832193285365\n",
      "epoch=228, loss=0.003902616464625771\n",
      "epoch=229, loss=0.003880687111755601\n",
      "epoch=230, loss=0.0038589914568430425\n",
      "epoch=231, loss=0.0038375258714476346\n",
      "epoch=232, loss=0.0038162868006757318\n",
      "epoch=233, loss=0.0037952707613486875\n",
      "epoch=234, loss=0.0037744743402249674\n",
      "epoch=235, loss=0.00375389419227438\n",
      "epoch=236, loss=0.0037335270390026773\n",
      "epoch=237, loss=0.0037133696668248026\n",
      "epoch=238, loss=0.003693418925485207\n",
      "epoch=239, loss=0.0036736717265236146\n",
      "epoch=240, loss=0.0036541250417847725\n",
      "epoch=241, loss=0.003634775901970703\n",
      "epoch=242, loss=0.0036156213952340645\n",
      "epoch=243, loss=0.003596658665811322\n",
      "epoch=244, loss=0.0035778849126943315\n",
      "epoch=245, loss=0.0035592973883392383\n",
      "epoch=246, loss=0.0035408933974113072\n",
      "epoch=247, loss=0.0035226702955647063\n",
      "epoch=248, loss=0.00350462548825599\n",
      "epoch=249, loss=0.003486756429590283\n",
      "epoch=250, loss=0.003469060621199072\n",
      "epoch=251, loss=0.003451535611148707\n",
      "epoch=252, loss=0.003434178992878497\n",
      "epoch=253, loss=0.003416988404167598\n",
      "epoch=254, loss=0.0033999615261297265\n",
      "epoch=255, loss=0.00338309608223492\n",
      "epoch=256, loss=0.003366389837357322\n",
      "epoch=257, loss=0.0033498405968484485\n",
      "epoch=258, loss=0.0033334462056349113\n",
      "epoch=259, loss=0.003317204547340038\n",
      "epoch=260, loss=0.0033011135434285054\n",
      "epoch=261, loss=0.0032851711523734393\n",
      "epoch=262, loss=0.00326937536884516\n",
      "epoch=263, loss=0.0032537242229210457\n",
      "epoch=264, loss=0.0032382157793157886\n",
      "epoch=265, loss=0.0032228481366314847\n",
      "epoch=266, loss=0.0032076194266269635\n",
      "epoch=267, loss=0.0031925278135057893\n",
      "epoch=268, loss=0.0031775714932223216\n",
      "epoch=269, loss=0.003162748692805462\n",
      "epoch=270, loss=0.0031480576696993616\n",
      "epoch=271, loss=0.0031334967111207607\n",
      "epoch=272, loss=0.003119064133432403\n",
      "epoch=273, loss=0.003104758281532114\n",
      "epoch=274, loss=0.003090577528256952\n",
      "epoch=275, loss=0.003076520273802247\n",
      "epoch=276, loss=0.003062584945154834\n",
      "epoch=277, loss=0.0030487699955402746\n",
      "epoch=278, loss=0.0030350739038835705\n",
      "epoch=279, loss=0.0030214951742830076\n",
      "epoch=280, loss=0.0030080323354967986\n",
      "epoch=281, loss=0.002994683940442109\n",
      "epoch=282, loss=0.0029814485657061562\n",
      "epoch=283, loss=0.0029683248110690505\n",
      "epoch=284, loss=0.0029553112990380126\n",
      "epoch=285, loss=0.0029424066743927117\n",
      "epoch=286, loss=0.002929609603741364\n",
      "epoch=287, loss=0.00291691877508735\n",
      "epoch=288, loss=0.002904332897406008\n",
      "epoch=289, loss=0.0028918507002313586\n",
      "epoch=290, loss=0.0028794709332525038\n",
      "epoch=291, loss=0.0028671923659194074\n",
      "epoch=292, loss=0.0028550137870578165\n",
      "epoch=293, loss=0.0028429340044931212\n",
      "epoch=294, loss=0.0028309518446827968\n",
      "epoch=295, loss=0.002819066152357365\n",
      "epoch=296, loss=0.0028072757901695246\n",
      "epoch=297, loss=0.002795579638351256\n",
      "epoch=298, loss=0.002783976594378741\n",
      "epoch=299, loss=0.002772465572644827\n",
      "epoch=300, loss=0.002761045504138927\n",
      "epoch=301, loss=0.0027497153361340193\n",
      "epoch=302, loss=0.0027384740318807436\n",
      "epoch=303, loss=0.0027273205703082426\n",
      "epoch=304, loss=0.0027162539457317014\n",
      "epoch=305, loss=0.0027052731675663174\n",
      "epoch=306, loss=0.002694377260047619\n",
      "epoch=307, loss=0.0026835652619578965\n",
      "epoch=308, loss=0.002672836226358652\n",
      "epoch=309, loss=0.0026621892203288785\n",
      "epoch=310, loss=0.0026516233247090228\n",
      "epoch=311, loss=0.0026411376338505337\n",
      "epoch=312, loss=0.0026307312553707613\n",
      "epoch=313, loss=0.0026204033099131874\n",
      "epoch=314, loss=0.002610152930912784\n",
      "epoch=315, loss=0.0025999792643663674\n",
      "epoch=316, loss=0.0025898814686078804\n",
      "epoch=317, loss=0.0025798587140884142\n",
      "epoch=318, loss=0.0025699101831609095\n",
      "epoch=319, loss=0.0025600350698694\n",
      "epoch=320, loss=0.0025502325797426536\n",
      "epoch=321, loss=0.002540501929592192\n",
      "epoch=322, loss=0.0025308423473144616\n",
      "epoch=323, loss=0.0025212530716972044\n",
      "epoch=324, loss=0.0025117333522297488\n",
      "epoch=325, loss=0.0025022824489173167\n",
      "epoch=326, loss=0.0024928996320990895\n",
      "epoch=327, loss=0.0024835841822700455\n",
      "epoch=328, loss=0.002474335389906437\n",
      "epoch=329, loss=0.002465152555294822\n",
      "epoch=330, loss=0.002456034988364578\n",
      "epoch=331, loss=0.002446982008523823\n",
      "epoch=332, loss=0.0024379929444986407\n",
      "epoch=333, loss=0.0024290671341755258\n",
      "epoch=334, loss=0.002420203924447035\n",
      "epoch=335, loss=0.0024114026710605136\n",
      "epoch=336, loss=0.002402662738469796\n",
      "epoch=337, loss=0.0023939834996899276\n",
      "epoch=338, loss=0.0023853643361547087\n",
      "epoch=339, loss=0.002376804637577094\n",
      "epoch=340, loss=0.002368303801812299\n",
      "epoch=341, loss=0.0023598612347236546\n",
      "epoch=342, loss=0.002351476350051016\n",
      "epoch=343, loss=0.002343148569281808\n",
      "epoch=344, loss=0.0023348773215245374\n",
      "epoch=345, loss=0.0023266620433847504\n",
      "epoch=346, loss=0.002318502178843449\n",
      "epoch=347, loss=0.002310397179137763\n",
      "epoch=348, loss=0.0023023465026440005\n",
      "epoch=349, loss=0.002294349614762869\n",
      "epoch=350, loss=0.0022864059878069426\n",
      "epoch=351, loss=0.002278515100890236\n",
      "epoch=352, loss=0.0022706764398198838\n",
      "epoch=353, loss=0.0022628894969898834\n",
      "epoch=354, loss=0.0022551537712768295\n",
      "epoch=355, loss=0.0022474687679376083\n",
      "epoch=356, loss=0.002239833998509016\n",
      "epoch=357, loss=0.002232248980709247\n",
      "epoch=358, loss=0.0022247132383412527\n",
      "epoch=359, loss=0.0022172263011978146\n",
      "epoch=360, loss=0.0022097877049685045\n",
      "epoch=361, loss=0.0022023969911482083\n",
      "epoch=362, loss=0.002195053706947485\n",
      "epoch=363, loss=0.002187757405204454\n",
      "epoch=364, loss=0.002180507644298376\n",
      "epoch=365, loss=0.0021733039880647695\n",
      "epoch=366, loss=0.002166146005712082\n",
      "epoch=367, loss=0.002159033271739898\n",
      "epoch=368, loss=0.0021519653658585683\n",
      "epoch=369, loss=0.0021449418729103504\n",
      "epoch=370, loss=0.0021379623827919576\n",
      "epoch=371, loss=0.002131026490378466\n",
      "epoch=372, loss=0.0021241337954485966\n",
      "epoch=373, loss=0.002117283902611368\n",
      "epoch=374, loss=0.0021104764212339887\n",
      "epoch=375, loss=0.0021037109653710803\n",
      "epoch=376, loss=0.0020969871536951376\n",
      "epoch=377, loss=0.0020903046094282052\n",
      "epoch=378, loss=0.002083662960274765\n",
      "epoch=379, loss=0.002077061838355799\n",
      "epoch=380, loss=0.00207050088014401\n",
      "epoch=381, loss=0.0020639797264001662\n",
      "epoch=382, loss=0.0020574980221105526\n",
      "epoch=383, loss=0.0020510554164255147\n",
      "epoch=384, loss=0.002044651562599049\n",
      "epoch=385, loss=0.002038286117929462\n",
      "epoch=386, loss=0.0020319587437010234\n",
      "epoch=387, loss=0.0020256691051266464\n",
      "epoch=388, loss=0.002019416871291506\n",
      "epoch=389, loss=0.0020132017150976647\n",
      "epoch=390, loss=0.002007023313209641\n",
      "epoch=391, loss=0.002000881346000839\n",
      "epoch=392, loss=0.001994775497500962\n",
      "epoch=393, loss=0.0019887054553442687\n",
      "epoch=394, loss=0.001982670910718719\n",
      "epoch=395, loss=0.001976671558315938\n",
      "epoch=396, loss=0.001970707096282091\n",
      "epoch=397, loss=0.001964777226169488\n",
      "epoch=398, loss=0.0019588816528890714\n",
      "epoch=399, loss=0.001953020084663641\n",
      "epoch=400, loss=0.0019471922329818649\n",
      "epoch=401, loss=0.0019413978125530913\n",
      "epoch=402, loss=0.0019356365412628372\n",
      "epoch=403, loss=0.0019299081401290578\n",
      "epoch=404, loss=0.0019242123332591102\n",
      "epoch=405, loss=0.0019185488478074366\n",
      "epoch=406, loss=0.0019129174139339159\n",
      "epoch=407, loss=0.0019073177647629033\n",
      "epoch=408, loss=0.001901749636342951\n",
      "epoch=409, loss=0.0018962127676071436\n",
      "epoch=410, loss=0.0018907069003341222\n",
      "epoch=411, loss=0.0018852317791096572\n",
      "epoch=412, loss=0.0018797871512889468\n",
      "epoch=413, loss=0.0018743727669594196\n",
      "epoch=414, loss=0.001868988378904183\n",
      "epoch=415, loss=0.0018636337425660464\n",
      "epoch=416, loss=0.0018583086160121058\n",
      "epoch=417, loss=0.0018530127598988938\n",
      "epoch=418, loss=0.0018477459374380914\n",
      "epoch=419, loss=0.0018425079143627526\n",
      "epoch=420, loss=0.0018372984588940972\n",
      "epoch=421, loss=0.0018321173417087907\n",
      "epoch=422, loss=0.0018269643359067526\n",
      "epoch=423, loss=0.0018218392169794787\n",
      "epoch=424, loss=0.001816741762778817\n",
      "epoch=425, loss=0.001811671753486272\n",
      "epoch=426, loss=0.0018066289715827739\n",
      "epoch=427, loss=0.0018016132018188727\n",
      "epoch=428, loss=0.0017966242311854678\n",
      "epoch=429, loss=0.0017916618488849115\n",
      "epoch=430, loss=0.0017867258463026192\n",
      "epoch=431, loss=0.0017818160169790474\n",
      "epoch=432, loss=0.001776932156582176\n",
      "epoch=433, loss=0.0017720740628803478\n",
      "epoch=434, loss=0.001767241535715539\n",
      "epoch=435, loss=0.0017624343769770537\n",
      "epoch=436, loss=0.0017576523905755838\n",
      "epoch=437, loss=0.0017528953824176839\n",
      "epoch=438, loss=0.0017481631603806337\n",
      "epoch=439, loss=0.0017434555342876299\n",
      "epoch=440, loss=0.0017387723158834285\n",
      "epoch=441, loss=0.001734113318810279\n",
      "epoch=442, loss=0.0017294783585842602\n",
      "epoch=443, loss=0.0017248672525719383\n",
      "epoch=444, loss=0.0017202798199673997\n",
      "epoch=445, loss=0.001715715881769606\n",
      "epoch=446, loss=0.0017111752607600755\n",
      "epoch=447, loss=0.0017066577814809198\n",
      "epoch=448, loss=0.0017021632702131676\n",
      "epoch=449, loss=0.0016976915549554539\n",
      "epoch=450, loss=0.0016932424654029557\n",
      "epoch=451, loss=0.0016888158329267015\n",
      "epoch=452, loss=0.0016844114905531279\n",
      "epoch=453, loss=0.001680029272943977\n",
      "epoch=454, loss=0.0016756690163764506\n",
      "epoch=455, loss=0.001671330558723663\n",
      "epoch=456, loss=0.0016670137394353777\n",
      "epoch=457, loss=0.001662718399519031\n",
      "epoch=458, loss=0.0016584443815209995\n",
      "epoch=459, loss=0.0016541915295081653\n",
      "epoch=460, loss=0.0016499596890497288\n",
      "epoch=461, loss=0.0016457487071992742\n",
      "epoch=462, loss=0.001641558432477107\n",
      "epoch=463, loss=0.0016373887148528356\n",
      "epoch=464, loss=0.001633239405728196\n",
      "epoch=465, loss=0.001629110357920116\n",
      "epoch=466, loss=0.001625001425644027\n",
      "epoch=467, loss=0.0016209124644974004\n",
      "epoch=468, loss=0.0016168433314435256\n",
      "epoch=469, loss=0.0016127938847955061\n",
      "epoch=470, loss=0.0016087639842004792\n",
      "epoch=471, loss=0.001604753490624061\n",
      "epoch=472, loss=0.0016007622663350032\n",
      "epoch=473, loss=0.0015967901748900678\n",
      "epoch=474, loss=0.001592837081119097\n",
      "epoch=475, loss=0.0015889028511103128\n",
      "epoch=476, loss=0.0015849873521957961\n",
      "epoch=477, loss=0.0015810904529371661\n",
      "epoch=478, loss=0.0015772120231114883\n",
      "epoch=479, loss=0.001573351933697319\n",
      "epoch=480, loss=0.0015695100568610093\n",
      "epoch=481, loss=0.001565686265943123\n",
      "epoch=482, loss=0.0015618804354450928\n",
      "epoch=483, loss=0.00155809244101605\n",
      "epoch=484, loss=0.0015543221594397862\n",
      "epoch=485, loss=0.0015505694686219638\n",
      "epoch=486, loss=0.0015468342475774373\n",
      "epoch=487, loss=0.0015431163764177839\n",
      "epoch=488, loss=0.0015394157363389717\n",
      "epoch=489, loss=0.001535732209609213\n",
      "epoch=490, loss=0.0015320656795569836\n",
      "epoch=491, loss=0.0015284160305591775\n",
      "epoch=492, loss=0.0015247831480294399\n",
      "epoch=493, loss=0.0015211669184066528\n",
      "epoch=494, loss=0.0015175672291435679\n",
      "epoch=495, loss=0.0015139839686955758\n",
      "epoch=496, loss=0.0015104170265096567\n",
      "epoch=497, loss=0.0015068662930134604\n",
      "epoch=498, loss=0.0015033316596045044\n",
      "epoch=499, loss=0.0014998130186395554\n",
      "epoch=500, loss=0.0014963102634241218\n",
      "epoch=501, loss=0.0014928232882021042\n",
      "epoch=502, loss=0.0014893519881455394\n",
      "epoch=503, loss=0.0014858962593445428\n",
      "epoch=504, loss=0.0014824559987973163\n",
      "epoch=505, loss=0.0014790311044003287\n",
      "epoch=506, loss=0.001475621474938599\n",
      "epoch=507, loss=0.0014722270100761207\n",
      "epoch=508, loss=0.0014688476103464003\n",
      "epoch=509, loss=0.0014654831771431088\n",
      "epoch=510, loss=0.0014621336127108784\n",
      "epoch=511, loss=0.001458798820136197\n",
      "epoch=512, loss=0.0014554787033384067\n",
      "epoch=513, loss=0.0014521731670608634\n",
      "epoch=514, loss=0.0014488821168621492\n",
      "epoch=515, loss=0.0014456054591074398\n",
      "epoch=516, loss=0.0014423431009599672\n",
      "epoch=517, loss=0.0014390949503725824\n",
      "epoch=518, loss=0.0014358609160794315\n",
      "epoch=519, loss=0.0014326409075877443\n",
      "epoch=520, loss=0.0014294348351697097\n",
      "epoch=521, loss=0.0014262426098544587\n",
      "epoch=522, loss=0.001423064143420162\n",
      "epoch=523, loss=0.0014198993483862013\n",
      "epoch=524, loss=0.0014167481380054478\n",
      "epoch=525, loss=0.0014136104262566511\n",
      "epoch=526, loss=0.0014104861278369067\n",
      "epoch=527, loss=0.0014073751581542093\n",
      "epoch=528, loss=0.0014042774333201196\n",
      "epoch=529, loss=0.0014011928701425115\n",
      "epoch=530, loss=0.0013981213861184016\n",
      "epoch=531, loss=0.0013950628994268668\n",
      "epoch=532, loss=0.0013920173289220738\n",
      "epoch=533, loss=0.0013889845941263512\n",
      "epoch=534, loss=0.0013859646152233854\n",
      "epoch=535, loss=0.0013829573130514777\n",
      "epoch=536, loss=0.001379962609096884\n",
      "epoch=537, loss=0.0013769804254872484\n",
      "epoch=538, loss=0.0013740106849850972\n",
      "epoch=539, loss=0.001371053310981435\n",
      "epoch=540, loss=0.0013681082274893887\n",
      "epoch=541, loss=0.0013651753591379524\n",
      "epoch=542, loss=0.001362254631165811\n",
      "epoch=543, loss=0.0013593459694151995\n",
      "epoch=544, loss=0.0013564493003258803\n",
      "epoch=545, loss=0.001353564550929169\n",
      "epoch=546, loss=0.0013506916488420354\n",
      "epoch=547, loss=0.0013478305222612795\n",
      "epoch=548, loss=0.0013449810999577646\n",
      "epoch=549, loss=0.0013421433112707408\n",
      "epoch=550, loss=0.0013393170861021996\n",
      "epoch=551, loss=0.0013365023549113373\n",
      "epoch=552, loss=0.0013336990487090518\n",
      "epoch=553, loss=0.0013309070990525247\n",
      "epoch=554, loss=0.0013281264380398477\n",
      "epoch=555, loss=0.0013253569983047203\n",
      "epoch=556, loss=0.0013225987130112242\n",
      "epoch=557, loss=0.0013198515158486328\n",
      "epoch=558, loss=0.0013171153410263072\n",
      "epoch=559, loss=0.0013143901232686224\n",
      "epoch=560, loss=0.0013116757978099687\n",
      "epoch=561, loss=0.001308972300389829\n",
      "epoch=562, loss=0.0013062795672478767\n",
      "epoch=563, loss=0.0013035975351191513\n",
      "epoch=564, loss=0.0013009261412292863\n",
      "epoch=565, loss=0.0012982653232897921\n",
      "epoch=566, loss=0.0012956150194933967\n",
      "epoch=567, loss=0.001292975168509427\n",
      "epoch=568, loss=0.00129034570947925\n",
      "epoch=569, loss=0.0012877265820117792\n",
      "epoch=570, loss=0.0012851177261790148\n",
      "epoch=571, loss=0.0012825190825116297\n",
      "epoch=572, loss=0.001279930591994629\n",
      "epoch=573, loss=0.0012773521960630337\n",
      "epoch=574, loss=0.0012747838365976423\n",
      "epoch=575, loss=0.0012722254559208036\n",
      "epoch=576, loss=0.001269676996792265\n",
      "epoch=577, loss=0.001267138402405054\n",
      "epoch=578, loss=0.0012646096163814286\n",
      "epoch=579, loss=0.001262090582768821\n",
      "epoch=580, loss=0.001259581246035891\n",
      "epoch=581, loss=0.0012570815510685766\n",
      "epoch=582, loss=0.0012545914431662147\n",
      "epoch=583, loss=0.00125211086803769\n",
      "epoch=584, loss=0.0012496397717976268\n",
      "epoch=585, loss=0.0012471781009626391\n",
      "epoch=586, loss=0.0012447258024476005\n",
      "epoch=587, loss=0.0012422828235619716\n",
      "epoch=588, loss=0.001239849112006163\n",
      "epoch=589, loss=0.001237424615867933\n",
      "epoch=590, loss=0.0012350092836188279\n",
      "epoch=591, loss=0.0012326030641106704\n",
      "epoch=592, loss=0.001230205906572068\n",
      "epoch=593, loss=0.0012278177606049878\n",
      "epoch=594, loss=0.0012254385761813183\n",
      "epoch=595, loss=0.001223068303639538\n",
      "epoch=596, loss=0.00122070689368136\n",
      "epoch=597, loss=0.0012183542973684446\n",
      "epoch=598, loss=0.0012160104661191364\n",
      "epoch=599, loss=0.0012136753517052372\n",
      "epoch=600, loss=0.001211348906248827\n",
      "epoch=601, loss=0.0012090310822190883\n",
      "epoch=602, loss=0.0012067218324292098\n",
      "epoch=603, loss=0.0012044211100332757\n",
      "epoch=604, loss=0.0012021288685232165\n",
      "epoch=605, loss=0.0011998450617257915\n",
      "epoch=606, loss=0.0011975696437996003\n",
      "epoch=607, loss=0.0011953025692321131\n",
      "epoch=608, loss=0.001193043792836751\n",
      "epoch=609, loss=0.001190793269749987\n",
      "epoch=610, loss=0.0011885509554284896\n",
      "epoch=611, loss=0.001186316805646268\n",
      "epoch=612, loss=0.001184090776491893\n",
      "epoch=613, loss=0.001181872824365698\n",
      "epoch=614, loss=0.0011796629059770431\n",
      "epoch=615, loss=0.001177460978341602\n",
      "epoch=616, loss=0.0011752669987786682\n",
      "epoch=617, loss=0.0011730809249084861\n",
      "epoch=618, loss=0.0011709027146496313\n",
      "epoch=619, loss=0.0011687323262163979\n",
      "epoch=620, loss=0.0011665697181162278\n",
      "epoch=621, loss=0.0011644148491471416\n",
      "epoch=622, loss=0.001162267678395234\n",
      "epoch=623, loss=0.0011601281652321588\n",
      "epoch=624, loss=0.0011579962693126695\n",
      "epoch=625, loss=0.0011558719505721609\n",
      "epoch=626, loss=0.0011537551692242542\n",
      "epoch=627, loss=0.0011516458857583917\n",
      "epoch=628, loss=0.001149544060937473\n",
      "epoch=629, loss=0.0011474496557954993\n",
      "epoch=630, loss=0.0011453626316352537\n",
      "epoch=631, loss=0.0011432829500259976\n",
      "epoch=632, loss=0.0011412105728012018\n",
      "epoch=633, loss=0.0011391454620562778\n",
      "epoch=634, loss=0.0011370875801463558\n",
      "epoch=635, loss=0.0011350368896840806\n",
      "epoch=636, loss=0.0011329933535374182\n",
      "epoch=637, loss=0.0011309569348274928\n",
      "epoch=638, loss=0.0011289275969264558\n",
      "epoch=639, loss=0.0011269053034553438\n",
      "epoch=640, loss=0.001124890018282002\n",
      "epoch=641, loss=0.0011228817055189955\n",
      "epoch=642, loss=0.0011208803295215503\n",
      "epoch=643, loss=0.0011188858548855272\n",
      "epoch=644, loss=0.0011168982464453932\n",
      "epoch=645, loss=0.0011149174692722367\n",
      "epoch=646, loss=0.001112943488671782\n",
      "epoch=647, loss=0.001110976270182445\n",
      "epoch=648, loss=0.0011090157795733853\n",
      "epoch=649, loss=0.001107061982842598\n",
      "epoch=650, loss=0.0011051148462150006\n",
      "epoch=651, loss=0.0011031743361405698\n",
      "epoch=652, loss=0.0011012404192924789\n",
      "epoch=653, loss=0.0010993130625652453\n",
      "epoch=654, loss=0.0010973922330729056\n",
      "epoch=655, loss=0.001095477898147222\n",
      "epoch=656, loss=0.00109357002533588\n",
      "epoch=657, loss=0.001091668582400725\n",
      "epoch=658, loss=0.001089773537316011\n",
      "epoch=659, loss=0.001087884858266647\n",
      "epoch=660, loss=0.0010860025136464984\n",
      "epoch=661, loss=0.0010841264720566712\n",
      "epoch=662, loss=0.0010822567023038275\n",
      "epoch=663, loss=0.0010803931733985156\n",
      "epoch=664, loss=0.0010785358545535152\n",
      "epoch=665, loss=0.0010766847151822097\n",
      "epoch=666, loss=0.0010748397248969421\n",
      "epoch=667, loss=0.001073000853507427\n",
      "epoch=668, loss=0.0010711680710191538\n",
      "epoch=669, loss=0.0010693413476318147\n",
      "epoch=670, loss=0.0010675206537377375\n",
      "epoch=671, loss=0.001065705959920334\n",
      "epoch=672, loss=0.0010638972369525928\n",
      "epoch=673, loss=0.001062094455795538\n",
      "epoch=674, loss=0.0010602975875967406\n",
      "epoch=675, loss=0.0010585066036888236\n",
      "epoch=676, loss=0.0010567214755880044\n",
      "epoch=677, loss=0.001054942174992614\n",
      "epoch=678, loss=0.001053168673781664\n",
      "epoch=679, loss=0.0010514009440134127\n",
      "epoch=680, loss=0.0010496389579239462\n",
      "epoch=681, loss=0.001047882687925778\n",
      "epoch=682, loss=0.0010461321066064472\n",
      "epoch=683, loss=0.0010443871867271497\n",
      "epoch=684, loss=0.0010426479012213671\n",
      "epoch=685, loss=0.0010409142231935246\n",
      "epoch=686, loss=0.0010391861259176273\n",
      "epoch=687, loss=0.001037463582835956\n",
      "epoch=688, loss=0.0010357465675577477\n",
      "epoch=689, loss=0.0010340350538578826\n",
      "epoch=690, loss=0.0010323290156756015\n",
      "epoch=691, loss=0.0010306284271132222\n",
      "epoch=692, loss=0.00102893326243488\n",
      "epoch=693, loss=0.001027243496065265\n",
      "epoch=694, loss=0.0010255591025883906\n",
      "epoch=695, loss=0.0010238800567463344\n",
      "epoch=696, loss=0.001022206333438055\n",
      "epoch=697, loss=0.0010205379077181487\n",
      "epoch=698, loss=0.0010188747547956764\n",
      "epoch=699, loss=0.0010172168500329603\n",
      "epoch=700, loss=0.0010155641689444143\n",
      "epoch=701, loss=0.001013916687195378\n",
      "epoch=702, loss=0.0010122743806009601\n",
      "epoch=703, loss=0.0010106372251248953\n",
      "epoch=704, loss=0.0010090051968784104\n",
      "epoch=705, loss=0.0010073782721190976\n",
      "epoch=706, loss=0.0010057564272498085\n",
      "epoch=707, loss=0.0010041396388175442\n",
      "epoch=708, loss=0.0010025278835123603\n",
      "epoch=709, loss=0.0010009211381662914\n",
      "epoch=710, loss=0.000999319379752274\n",
      "epoch=711, loss=0.0009977225853830735\n",
      "epoch=712, loss=0.0009961307323102522\n",
      "epoch=713, loss=0.0009945437979230942\n",
      "epoch=714, loss=0.000992961759747598\n",
      "epoch=715, loss=0.0009913845954454337\n",
      "epoch=716, loss=0.0009898122828129313\n",
      "epoch=717, loss=0.0009882447997800767\n",
      "epoch=718, loss=0.000986682124409496\n",
      "epoch=719, loss=0.0009851242348954921\n",
      "epoch=720, loss=0.0009835711095630426\n",
      "epoch=721, loss=0.000982022726866834\n",
      "epoch=722, loss=0.0009804790653903013\n",
      "epoch=723, loss=0.000978940103844663\n",
      "epoch=724, loss=0.0009774058210679894\n",
      "epoch=725, loss=0.0009758761960242511\n",
      "epoch=726, loss=0.0009743512078023914\n",
      "epoch=727, loss=0.0009728308356154101\n",
      "epoch=728, loss=0.0009713150587994443\n",
      "epoch=729, loss=0.0009698038568128673\n",
      "epoch=730, loss=0.0009682972092353848\n",
      "epoch=731, loss=0.0009667950957671457\n",
      "epoch=732, loss=0.0009652974962278723\n",
      "epoch=733, loss=0.0009638043905559588\n",
      "epoch=734, loss=0.0009623157588076391\n",
      "epoch=735, loss=0.0009608315811560978\n",
      "epoch=736, loss=0.0009593518378906425\n",
      "epoch=737, loss=0.000957876509415834\n",
      "epoch=738, loss=0.0009564055762506699\n",
      "epoch=739, loss=0.0009549390190277466\n",
      "epoch=740, loss=0.0009534768184924375\n",
      "epoch=741, loss=0.0009520189555020836\n",
      "epoch=742, loss=0.0009505654110251668\n",
      "epoch=743, loss=0.0009491161661405305\n",
      "epoch=744, loss=0.0009476712020365781\n",
      "epoch=745, loss=0.0009462305000104721\n",
      "epoch=746, loss=0.0009447940414673692\n",
      "epoch=747, loss=0.0009433618079196405\n",
      "epoch=748, loss=0.000941933780986102\n",
      "epoch=749, loss=0.0009405099423912608\n",
      "epoch=750, loss=0.000939090273964549\n",
      "epoch=751, loss=0.0009376747576395782\n",
      "epoch=752, loss=0.0009362633754534106\n",
      "epoch=753, loss=0.0009348561095458018\n",
      "epoch=754, loss=0.0009334529421584989\n",
      "epoch=755, loss=0.000932053855634489\n",
      "epoch=756, loss=0.0009306588324172983\n",
      "epoch=757, loss=0.0009292678550502816\n",
      "epoch=758, loss=0.0009278809061759098\n",
      "epoch=759, loss=0.0009264979685350762\n",
      "epoch=760, loss=0.0009251190249664062\n",
      "epoch=761, loss=0.0009237440584055596\n",
      "epoch=762, loss=0.0009223730518845577\n",
      "epoch=763, loss=0.0009210059885311126\n",
      "epoch=764, loss=0.0009196428515679352\n",
      "epoch=765, loss=0.0009182836243121027\n",
      "epoch=766, loss=0.0009169282901743645\n",
      "epoch=767, loss=0.000915576832658525\n",
      "epoch=768, loss=0.0009142292353607594\n",
      "epoch=769, loss=0.0009128854819690024\n",
      "epoch=770, loss=0.0009115455562622934\n",
      "epoch=771, loss=0.0009102094421101465\n",
      "epoch=772, loss=0.000908877123471922\n",
      "epoch=773, loss=0.0009075485843962144\n",
      "epoch=774, loss=0.0009062238090202306\n",
      "epoch=775, loss=0.0009049027815691791\n",
      "epoch=776, loss=0.0009035854863556487\n",
      "epoch=777, loss=0.0009022719077790413\n",
      "epoch=778, loss=0.000900962030324938\n",
      "epoch=779, loss=0.0008996558385645324\n",
      "epoch=780, loss=0.0008983533171540417\n",
      "epoch=781, loss=0.0008970544508341052\n",
      "epoch=782, loss=0.00089575922442923\n",
      "epoch=783, loss=0.0008944676228472114\n",
      "epoch=784, loss=0.0008931796310785589\n",
      "epoch=785, loss=0.0008918952341959418\n",
      "epoch=786, loss=0.0008906144173536218\n",
      "epoch=787, loss=0.0008893371657869099\n",
      "epoch=788, loss=0.0008880634648116038\n",
      "epoch=789, loss=0.0008867932998234523\n",
      "epoch=790, loss=0.000885526656297619\n",
      "epoch=791, loss=0.00088426351978813\n",
      "epoch=792, loss=0.0008830038759273508\n",
      "epoch=793, loss=0.000881747710425469\n",
      "epoch=794, loss=0.0008804950090699498\n",
      "epoch=795, loss=0.0008792457577250335\n",
      "epoch=796, loss=0.00087799994233121\n",
      "epoch=797, loss=0.0008767575489047166\n",
      "epoch=798, loss=0.0008755185635370278\n",
      "epoch=799, loss=0.0008742829723943474\n",
      "epoch=800, loss=0.0008730507617171138\n",
      "epoch=801, loss=0.0008718219178195116\n",
      "epoch=802, loss=0.0008705964270889693\n",
      "epoch=803, loss=0.000869374275985674\n",
      "epoch=804, loss=0.0008681554510421006\n",
      "epoch=805, loss=0.0008669399388625134\n",
      "epoch=806, loss=0.0008657277261225097\n",
      "epoch=807, loss=0.0008645187995685369\n",
      "epoch=808, loss=0.0008633131460174224\n",
      "epoch=809, loss=0.0008621107523559141\n",
      "epoch=810, loss=0.0008609116055402281\n",
      "epoch=811, loss=0.0008597156925955689\n",
      "epoch=812, loss=0.0008585230006157016\n",
      "epoch=813, loss=0.0008573335167624849\n",
      "epoch=814, loss=0.0008561472282654287\n",
      "epoch=815, loss=0.0008549641224212542\n",
      "epoch=816, loss=0.0008537841865934602\n",
      "epoch=817, loss=0.0008526074082118643\n",
      "epoch=818, loss=0.0008514337747721971\n",
      "epoch=819, loss=0.0008502632738356609\n",
      "epoch=820, loss=0.0008490958930284996\n",
      "epoch=821, loss=0.0008479316200415872\n",
      "epoch=822, loss=0.0008467704426299946\n",
      "epoch=823, loss=0.0008456123486125917\n",
      "epoch=824, loss=0.0008444573258716121\n",
      "epoch=825, loss=0.0008433053623522655\n",
      "epoch=826, loss=0.000842156446062322\n",
      "epoch=827, loss=0.0008410105650716947\n",
      "epoch=828, loss=0.0008398677075120718\n",
      "epoch=829, loss=0.0008387278615764856\n",
      "epoch=830, loss=0.0008375910155189402\n",
      "epoch=831, loss=0.0008364571576540127\n",
      "epoch=832, loss=0.0008353262763564646\n",
      "epoch=833, loss=0.0008341983600608553\n",
      "epoch=834, loss=0.0008330733972611732\n",
      "epoch=835, loss=0.0008319513765104352\n",
      "epoch=836, loss=0.0008308322864203196\n",
      "epoch=837, loss=0.0008297161156608074\n",
      "epoch=838, loss=0.000828602852959787\n",
      "epoch=839, loss=0.0008274924871026994\n",
      "epoch=840, loss=0.0008263850069321706\n",
      "epoch=841, loss=0.0008252804013476572\n",
      "epoch=842, loss=0.0008241786593050685\n",
      "epoch=843, loss=0.0008230797698164292\n",
      "epoch=844, loss=0.0008219837219495192\n",
      "epoch=845, loss=0.0008208905048275072\n",
      "epoch=846, loss=0.0008198001076286268\n",
      "epoch=847, loss=0.000818712519585815\n",
      "epoch=848, loss=0.0008176277299863673\n",
      "epoch=849, loss=0.0008165457281716036\n",
      "epoch=850, loss=0.0008154665035365326\n",
      "epoch=851, loss=0.0008143900455295013\n",
      "epoch=852, loss=0.0008133163436518754\n",
      "epoch=853, loss=0.0008122453874577026\n",
      "epoch=854, loss=0.0008111771665533847\n",
      "epoch=855, loss=0.0008101116705973559\n",
      "epoch=856, loss=0.0008090488892997473\n",
      "epoch=857, loss=0.0008079888124220839\n",
      "epoch=858, loss=0.0008069314297769449\n",
      "epoch=859, loss=0.000805876731227672\n",
      "epoch=860, loss=0.0008048247066880206\n",
      "epoch=861, loss=0.0008037753461218925\n",
      "epoch=862, loss=0.0008027286395429803\n",
      "epoch=863, loss=0.0008016845770144977\n",
      "epoch=864, loss=0.000800643148648855\n",
      "epoch=865, loss=0.0007996043446073597\n",
      "epoch=866, loss=0.0007985681550999166\n",
      "epoch=867, loss=0.0007975345703847313\n",
      "epoch=868, loss=0.0007965035807680102\n",
      "epoch=869, loss=0.0007954751766036726\n",
      "epoch=870, loss=0.0007944493482930569\n",
      "epoch=871, loss=0.0007934260862846211\n",
      "epoch=872, loss=0.0007924053810736735\n",
      "epoch=873, loss=0.0007913872232020715\n",
      "epoch=874, loss=0.0007903716032579488\n",
      "epoch=875, loss=0.0007893585118754237\n",
      "epoch=876, loss=0.0007883479397343295\n",
      "epoch=877, loss=0.0007873398775599333\n",
      "epoch=878, loss=0.0007863343161226614\n",
      "epoch=879, loss=0.000785331246237825\n",
      "epoch=880, loss=0.0007843306587653474\n",
      "epoch=881, loss=0.0007833325446094992\n",
      "epoch=882, loss=0.0007823368947186274\n",
      "epoch=883, loss=0.0007813437000848954\n",
      "epoch=884, loss=0.0007803529517440115\n",
      "epoch=885, loss=0.0007793646407749672\n",
      "epoch=886, loss=0.0007783787582997901\n",
      "epoch=887, loss=0.0007773952954832725\n",
      "epoch=888, loss=0.0007764142435327208\n",
      "epoch=889, loss=0.0007754355936976984\n",
      "epoch=890, loss=0.0007744593372697766\n",
      "epoch=891, loss=0.0007734854655822881\n",
      "epoch=892, loss=0.0007725139700100668\n",
      "epoch=893, loss=0.0007715448419692072\n",
      "epoch=894, loss=0.0007705780729168209\n",
      "epoch=895, loss=0.0007696136543507896\n",
      "epoch=896, loss=0.0007686515778095334\n",
      "epoch=897, loss=0.000767691834871744\n",
      "epoch=898, loss=0.0007667344171561827\n",
      "epoch=899, loss=0.0007657793163214156\n",
      "epoch=900, loss=0.0007648265240655862\n",
      "epoch=901, loss=0.000763876032126192\n",
      "epoch=902, loss=0.0007629278322798419\n",
      "epoch=903, loss=0.0007619819163420252\n",
      "epoch=904, loss=0.0007610382761668919\n",
      "epoch=905, loss=0.0007600969036470183\n",
      "epoch=906, loss=0.0007591577907131826\n",
      "epoch=907, loss=0.0007582209293341486\n",
      "epoch=908, loss=0.0007572863115164338\n",
      "epoch=909, loss=0.0007563539293040895\n",
      "epoch=910, loss=0.0007554237747784951\n",
      "epoch=911, loss=0.000754495840058118\n",
      "epoch=912, loss=0.0007535701172983188\n",
      "epoch=913, loss=0.0007526465986911272\n",
      "epoch=914, loss=0.000751725276465026\n",
      "epoch=915, loss=0.0007508061428847446\n",
      "epoch=916, loss=0.0007498891902510507\n",
      "epoch=917, loss=0.0007489744109005329\n",
      "epoch=918, loss=0.0007480617972054096\n",
      "epoch=919, loss=0.000747151341573298\n",
      "epoch=920, loss=0.0007462430364470347\n",
      "epoch=921, loss=0.0007453368743044658\n",
      "epoch=922, loss=0.0007444328476582333\n",
      "epoch=923, loss=0.0007435309490555827\n",
      "epoch=924, loss=0.0007426311710781791\n",
      "epoch=925, loss=0.0007417335063418855\n",
      "epoch=926, loss=0.0007408379474965753\n",
      "epoch=927, loss=0.00073994448722595\n",
      "epoch=928, loss=0.0007390531182473243\n",
      "epoch=929, loss=0.0007381638333114515\n",
      "epoch=930, loss=0.0007372766252023247\n",
      "epoch=931, loss=0.000736391486736992\n",
      "epoch=932, loss=0.0007355084107653662\n",
      "epoch=933, loss=0.0007346273901700252\n",
      "epoch=934, loss=0.0007337484178660528\n",
      "epoch=935, loss=0.0007328714868008354\n",
      "epoch=936, loss=0.0007319965899538834\n",
      "epoch=937, loss=0.0007311237203366459\n",
      "epoch=938, loss=0.0007302528709923361\n",
      "epoch=939, loss=0.0007293840349957497\n",
      "epoch=940, loss=0.0007285172054530881\n",
      "epoch=941, loss=0.0007276523755017773\n",
      "epoch=942, loss=0.0007267895383102919\n",
      "epoch=943, loss=0.0007259286870779914\n",
      "epoch=944, loss=0.0007250698150349259\n",
      "epoch=945, loss=0.0007242129154416901\n",
      "epoch=946, loss=0.0007233579815892245\n",
      "epoch=947, loss=0.0007225050067986719\n",
      "epoch=948, loss=0.0007216539844211869\n",
      "epoch=949, loss=0.0007208049078377803\n",
      "epoch=950, loss=0.0007199577704591515\n",
      "epoch=951, loss=0.000719112565725517\n",
      "epoch=952, loss=0.0007182692871064508\n",
      "epoch=953, loss=0.0007174279281007255\n",
      "epoch=954, loss=0.0007165884822361362\n",
      "epoch=955, loss=0.0007157509430693545\n",
      "epoch=956, loss=0.000714915304185755\n",
      "epoch=957, loss=0.0007140815591992711\n",
      "epoch=958, loss=0.0007132497017522252\n",
      "epoch=959, loss=0.000712419725515177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=960, loss=0.0007115916241867606\n",
      "epoch=961, loss=0.0007107653914935472\n",
      "epoch=962, loss=0.0007099410211898666\n",
      "epoch=963, loss=0.0007091185070576768\n",
      "epoch=964, loss=0.0007082978429063958\n",
      "epoch=965, loss=0.0007074790225727641\n",
      "epoch=966, loss=0.0007066620399206793\n",
      "epoch=967, loss=0.0007058468888410683\n",
      "epoch=968, loss=0.0007050335632517157\n",
      "epoch=969, loss=0.0007042220570971375\n",
      "epoch=970, loss=0.0007034123643484219\n",
      "epoch=971, loss=0.0007026044790030907\n",
      "epoch=972, loss=0.0007017983950849485\n",
      "epoch=973, loss=0.0007009941066439529\n",
      "epoch=974, loss=0.0007001916077560555\n",
      "epoch=975, loss=0.0006993908925230799\n",
      "epoch=976, loss=0.0006985919550725524\n",
      "epoch=977, loss=0.0006977947895575983\n",
      "epoch=978, loss=0.0006969993901567765\n",
      "epoch=979, loss=0.000696205751073956\n",
      "epoch=980, loss=0.0006954138665381655\n",
      "epoch=981, loss=0.0006946237308034802\n",
      "epoch=982, loss=0.0006938353381488594\n",
      "epoch=983, loss=0.000693048682878036\n",
      "epoch=984, loss=0.0006922637593193634\n",
      "epoch=985, loss=0.000691480561825699\n",
      "epoch=986, loss=0.0006906990847742698\n",
      "epoch=987, loss=0.0006899193225665295\n",
      "epoch=988, loss=0.0006891412696280466\n",
      "epoch=989, loss=0.0006883649204083592\n",
      "epoch=990, loss=0.0006875902693808553\n",
      "epoch=991, loss=0.0006868173110426493\n",
      "epoch=992, loss=0.000686046039914444\n",
      "epoch=993, loss=0.0006852764505404147\n",
      "epoch=994, loss=0.0006845085374880792\n",
      "epoch=995, loss=0.0006837422953481727\n",
      "epoch=996, loss=0.0006829777187345339\n",
      "epoch=997, loss=0.0006822148022839661\n",
      "epoch=998, loss=0.0006814535406561298\n",
      "epoch=999, loss=0.0006806939285334164\n",
      "[[3.72876470e-05]\n",
      " [9.64983439e-01]\n",
      " [9.61449278e-01]\n",
      " [2.72483674e-03]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "model = Model()\n",
    "model.add(Linear(2, 3))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Linear(3, 1))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "model.set_loss(MSELoss)\n",
    "model.train(X, y, epochs=1000, learning_rate=0.1)\n",
    "\n",
    "predictions = model.predict(X)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, loss=10.803965146945673\n",
      "epoch=0, loss=10.717711291696356\n",
      "epoch=0, loss=10.94213276844914\n",
      "epoch=0, loss=10.73386338092749\n",
      "epoch=0, loss=10.73069152793749\n",
      "epoch=0, loss=10.726844508349833\n",
      "epoch=0, loss=10.71624650221188\n",
      "epoch=0, loss=10.580714668721834\n",
      "epoch=0, loss=10.803319664884851\n",
      "epoch=0, loss=10.67726164571343\n",
      "epoch=0, loss=10.605684776818466\n",
      "epoch=0, loss=10.590747177168273\n",
      "epoch=0, loss=10.844783096060144\n",
      "epoch=0, loss=10.555626921612205\n",
      "epoch=0, loss=10.681467881972907\n",
      "epoch=0, loss=10.6296962326693\n",
      "epoch=0, loss=10.703142324901497\n",
      "epoch=0, loss=10.55598889695597\n",
      "epoch=0, loss=10.401677660358345\n",
      "epoch=0, loss=10.61549000822691\n",
      "epoch=0, loss=10.598286894209084\n",
      "epoch=0, loss=10.504289683296696\n",
      "epoch=0, loss=10.472057420050366\n",
      "epoch=0, loss=10.454608306534878\n",
      "epoch=0, loss=10.36555417044579\n",
      "epoch=0, loss=10.359146730131911\n",
      "epoch=0, loss=10.72079548756025\n",
      "epoch=0, loss=10.524509107598382\n",
      "epoch=0, loss=10.62787727934509\n",
      "epoch=0, loss=10.355153317278704\n",
      "epoch=0, loss=10.29467785254661\n",
      "epoch=0, loss=10.404016667817494\n",
      "epoch=0, loss=10.378829906896755\n",
      "epoch=0, loss=10.437563451339525\n",
      "epoch=0, loss=10.3976762565423\n",
      "epoch=0, loss=10.422986080145654\n",
      "epoch=0, loss=10.351446984036293\n",
      "epoch=0, loss=10.247400750539352\n",
      "epoch=0, loss=10.374228912369936\n",
      "epoch=0, loss=10.30146961428004\n",
      "epoch=0, loss=10.478158244599776\n",
      "epoch=0, loss=10.363254933127742\n",
      "epoch=0, loss=10.49470549656344\n",
      "epoch=0, loss=10.503771033583691\n",
      "epoch=0, loss=10.285751374578824\n",
      "epoch=0, loss=10.415078610768386\n",
      "epoch=0, loss=10.390118446653236\n",
      "epoch=0, loss=10.23925421595527\n",
      "epoch=0, loss=10.392903121947283\n",
      "epoch=0, loss=10.235715497686881\n",
      "epoch=0, loss=10.363518532098546\n",
      "epoch=0, loss=10.202563260307347\n",
      "epoch=0, loss=10.119423497668933\n",
      "epoch=0, loss=10.25543031931742\n",
      "epoch=0, loss=10.141763211275846\n",
      "epoch=0, loss=10.251292085431027\n",
      "epoch=0, loss=10.531828377800581\n",
      "epoch=0, loss=10.309136409863209\n",
      "epoch=0, loss=10.264181611028093\n",
      "epoch=0, loss=10.15505081252786\n",
      "epoch=0, loss=10.169269751687773\n",
      "epoch=0, loss=10.17008641412374\n",
      "epoch=0, loss=10.220740028405965\n",
      "epoch=0, loss=10.350975136427458\n",
      "epoch=0, loss=10.351925689181067\n",
      "epoch=0, loss=10.44082833592987\n",
      "epoch=0, loss=10.026318173429216\n",
      "epoch=0, loss=10.283922289961597\n",
      "epoch=0, loss=10.21219379013719\n",
      "epoch=0, loss=10.182353970879165\n",
      "epoch=0, loss=9.716507448000993\n",
      "epoch=0, loss=10.026573205907178\n",
      "epoch=0, loss=9.968148148265639\n",
      "epoch=0, loss=10.26236749460297\n",
      "epoch=0, loss=9.960001325423963\n",
      "epoch=0, loss=10.080109063925445\n",
      "epoch=0, loss=10.019915802343665\n",
      "epoch=0, loss=10.08339168782991\n",
      "epoch=0, loss=10.171103665767479\n",
      "epoch=0, loss=9.906941713209921\n",
      "epoch=0, loss=10.178973869236748\n",
      "epoch=0, loss=9.8361901777087\n",
      "epoch=0, loss=9.993307726462211\n",
      "epoch=0, loss=10.040824789865056\n",
      "epoch=0, loss=10.051606369153134\n",
      "epoch=0, loss=9.897896759596039\n",
      "epoch=0, loss=9.938415716923505\n",
      "epoch=0, loss=10.04623122962114\n",
      "epoch=0, loss=10.394454253040493\n",
      "epoch=0, loss=10.126781398509136\n",
      "epoch=0, loss=10.084696966143843\n",
      "epoch=0, loss=9.905305817408843\n",
      "epoch=0, loss=9.654731992908484\n",
      "epoch=0, loss=9.863681262961602\n",
      "epoch=0, loss=9.828480822424272\n",
      "epoch=0, loss=10.3003847279842\n",
      "epoch=0, loss=9.836935566644812\n",
      "epoch=0, loss=9.647556334421727\n",
      "epoch=0, loss=10.079756812235976\n",
      "epoch=0, loss=9.636166118484722\n",
      "epoch=0, loss=9.698897019339174\n",
      "epoch=0, loss=10.178798094828082\n",
      "epoch=0, loss=9.887511320520582\n",
      "epoch=0, loss=10.162541604674448\n",
      "epoch=0, loss=9.766781786179722\n",
      "epoch=0, loss=9.740106933636966\n",
      "epoch=0, loss=9.971879131511571\n",
      "epoch=0, loss=10.049438859050142\n",
      "epoch=0, loss=9.934329792342622\n",
      "epoch=0, loss=10.10989153951081\n",
      "epoch=0, loss=9.753099280823252\n",
      "epoch=0, loss=9.887890971512919\n",
      "epoch=0, loss=9.678677750720315\n",
      "epoch=0, loss=10.070408400383666\n",
      "epoch=0, loss=9.763367345668907\n",
      "epoch=0, loss=9.836353462678812\n",
      "epoch=0, loss=9.973681841861879\n",
      "epoch=0, loss=9.708859596618534\n",
      "epoch=0, loss=9.856318794623657\n",
      "epoch=0, loss=9.608174286214028\n",
      "epoch=0, loss=9.80871289008633\n",
      "epoch=0, loss=9.741393976416235\n",
      "epoch=0, loss=9.602133097309334\n",
      "epoch=0, loss=9.347479177427058\n",
      "epoch=0, loss=9.570435357883127\n",
      "epoch=0, loss=9.304550078767234\n",
      "epoch=0, loss=9.957596516624507\n",
      "epoch=0, loss=9.780099058738218\n",
      "epoch=0, loss=9.714784103263055\n",
      "epoch=0, loss=9.642449153650922\n",
      "epoch=0, loss=9.649880461214845\n",
      "epoch=0, loss=9.946644552637892\n",
      "epoch=0, loss=10.019322407080782\n",
      "epoch=0, loss=9.801107527223257\n",
      "epoch=0, loss=9.514572594510978\n",
      "epoch=0, loss=10.023068163518095\n",
      "epoch=0, loss=9.625924382309607\n",
      "epoch=0, loss=9.831169366450698\n",
      "epoch=0, loss=9.735936788759277\n",
      "epoch=0, loss=10.104139953671332\n",
      "epoch=0, loss=9.918150787122954\n",
      "epoch=0, loss=9.96568084045184\n",
      "epoch=0, loss=9.670877772249433\n",
      "epoch=0, loss=9.330070232524895\n",
      "epoch=0, loss=9.234024102771038\n",
      "epoch=0, loss=9.625559464131097\n",
      "epoch=0, loss=9.88662501647525\n",
      "epoch=0, loss=9.81097959389253\n",
      "epoch=0, loss=9.145231267808393\n",
      "epoch=0, loss=9.498017629954434\n",
      "epoch=0, loss=9.548663170454576\n",
      "epoch=0, loss=9.255182337127497\n",
      "epoch=0, loss=9.312951143261929\n",
      "epoch=0, loss=9.69816774232936\n",
      "epoch=0, loss=9.763468075103829\n",
      "epoch=0, loss=9.68760095273799\n",
      "epoch=0, loss=9.423274635586573\n",
      "epoch=0, loss=9.177476543727094\n",
      "epoch=0, loss=9.374468244049469\n",
      "epoch=0, loss=9.120543185077118\n",
      "epoch=0, loss=9.495204339939372\n",
      "epoch=0, loss=9.782949991476448\n",
      "epoch=0, loss=9.636941619791097\n",
      "epoch=0, loss=9.378852886100612\n",
      "epoch=0, loss=9.859295581716633\n",
      "epoch=0, loss=9.790072858938048\n",
      "epoch=0, loss=9.698400662305023\n",
      "epoch=0, loss=9.520605306478831\n",
      "epoch=0, loss=9.568645365627994\n",
      "epoch=0, loss=9.426352841289322\n",
      "epoch=0, loss=9.661653964204602\n",
      "epoch=0, loss=9.917356450423215\n",
      "epoch=0, loss=9.559973537517\n",
      "epoch=0, loss=9.457778601677944\n",
      "epoch=0, loss=9.186510146160014\n",
      "epoch=0, loss=9.935816213416457\n",
      "epoch=0, loss=9.401534707249006\n",
      "epoch=0, loss=9.082418818488295\n",
      "epoch=0, loss=9.411228651706914\n",
      "epoch=0, loss=9.907356297386954\n",
      "epoch=0, loss=9.184660492007305\n",
      "epoch=0, loss=9.5688623990122\n",
      "epoch=0, loss=9.726906163826378\n",
      "epoch=0, loss=9.410667580617536\n",
      "epoch=0, loss=9.702161238056402\n",
      "epoch=0, loss=9.367333715802403\n",
      "epoch=0, loss=9.372086217001538\n",
      "epoch=0, loss=9.557843568896487\n",
      "epoch=0, loss=9.785111663880949\n",
      "epoch=0, loss=9.360591461437131\n",
      "epoch=0, loss=9.405233192830412\n",
      "epoch=0, loss=9.52903409381028\n",
      "epoch=0, loss=9.12343567208952\n",
      "epoch=0, loss=9.194069390997381\n",
      "epoch=0, loss=9.385718110494746\n",
      "epoch=0, loss=9.431160652397896\n",
      "epoch=0, loss=9.388159251405792\n",
      "epoch=0, loss=9.372471167090197\n",
      "epoch=0, loss=9.538064782830086\n",
      "epoch=0, loss=9.462128769926192\n",
      "epoch=0, loss=9.23251588025229\n",
      "epoch=0, loss=9.225006418900485\n",
      "epoch=0, loss=9.458241015699329\n",
      "epoch=0, loss=9.657420905141844\n",
      "epoch=0, loss=9.207416042281858\n",
      "epoch=0, loss=9.357897110167809\n",
      "epoch=0, loss=9.194879224010302\n",
      "epoch=0, loss=9.133610471280523\n",
      "epoch=0, loss=9.024570873717504\n",
      "epoch=0, loss=9.569250519035565\n",
      "epoch=0, loss=9.645906429984043\n",
      "epoch=0, loss=9.078448011784875\n",
      "epoch=0, loss=9.222788507549096\n",
      "epoch=0, loss=9.535718194178456\n",
      "epoch=0, loss=9.221377865127309\n",
      "epoch=0, loss=9.163677756562793\n",
      "epoch=0, loss=9.24703450072077\n",
      "epoch=0, loss=9.51242714878917\n",
      "epoch=0, loss=9.344189615629276\n",
      "epoch=0, loss=9.222534067514905\n",
      "epoch=0, loss=9.44432551878525\n",
      "epoch=0, loss=9.405086167992462\n",
      "epoch=0, loss=9.531761780424423\n",
      "epoch=0, loss=8.858918063258692\n",
      "epoch=0, loss=9.216312485531239\n",
      "epoch=0, loss=9.614318566264158\n",
      "epoch=0, loss=9.190335982932961\n",
      "epoch=0, loss=9.205835075379175\n",
      "epoch=0, loss=9.559791021541736\n",
      "epoch=0, loss=9.478333768836196\n",
      "epoch=0, loss=9.118247163111029\n",
      "epoch=0, loss=8.966804665017094\n",
      "epoch=0, loss=9.025272511449876\n",
      "epoch=0, loss=9.341643049999167\n",
      "epoch=0, loss=9.007026806419232\n",
      "epoch=0, loss=8.954444532436897\n",
      "epoch=0, loss=8.995995076151356\n",
      "epoch=0, loss=8.810431421438528\n",
      "epoch=0, loss=9.437063312769178\n",
      "epoch=0, loss=9.044210933997087\n",
      "epoch=0, loss=9.319281045126198\n",
      "epoch=0, loss=8.861299975031795\n",
      "epoch=0, loss=8.759888395302015\n",
      "epoch=0, loss=8.81947105152539\n",
      "epoch=0, loss=9.203193276006504\n",
      "epoch=0, loss=9.100068041907404\n",
      "epoch=0, loss=9.155504157333922\n",
      "epoch=0, loss=8.950063267275736\n",
      "epoch=0, loss=8.660696690242533\n",
      "epoch=0, loss=9.327490111016312\n",
      "epoch=0, loss=9.296330192451213\n",
      "epoch=0, loss=9.374116849264627\n",
      "epoch=0, loss=9.003651631639638\n",
      "epoch=0, loss=9.014340022590277\n",
      "epoch=0, loss=8.992292106380996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, loss=8.775674489216499\n",
      "epoch=0, loss=9.2807712970578\n",
      "epoch=0, loss=9.210607528407067\n",
      "epoch=0, loss=8.706976676095788\n",
      "epoch=0, loss=8.859109452595368\n",
      "epoch=0, loss=9.031231018785865\n",
      "epoch=0, loss=8.94110525127719\n",
      "epoch=0, loss=8.787835097168164\n",
      "epoch=0, loss=8.8552463229583\n",
      "epoch=0, loss=9.075761920832644\n",
      "epoch=0, loss=9.025981446312262\n",
      "epoch=0, loss=9.029914609725585\n",
      "epoch=0, loss=9.349298271439228\n",
      "epoch=0, loss=8.933206194366239\n",
      "epoch=0, loss=9.460028659421157\n",
      "epoch=0, loss=9.341601097381579\n",
      "epoch=0, loss=8.956456347447354\n",
      "epoch=0, loss=9.2034464447335\n",
      "epoch=0, loss=9.240982325019054\n",
      "epoch=0, loss=9.40460646821562\n",
      "epoch=0, loss=8.988757393805814\n",
      "epoch=0, loss=8.823014346189757\n",
      "epoch=0, loss=9.122441215533074\n",
      "epoch=0, loss=8.88713560531975\n",
      "epoch=0, loss=8.521330640673606\n",
      "epoch=0, loss=9.159147992551706\n",
      "epoch=0, loss=9.262094231482573\n",
      "epoch=0, loss=9.192710154145832\n",
      "epoch=0, loss=8.932489364323612\n",
      "epoch=0, loss=8.972043713699895\n",
      "epoch=0, loss=9.1633109093931\n",
      "epoch=0, loss=9.066200112035203\n",
      "epoch=0, loss=9.049615259636822\n",
      "epoch=0, loss=8.704441431065556\n",
      "epoch=0, loss=9.38188442786483\n",
      "epoch=0, loss=8.722724297848632\n",
      "epoch=0, loss=8.77432060895932\n",
      "epoch=0, loss=9.24733013408629\n",
      "epoch=0, loss=9.137835098622858\n",
      "epoch=0, loss=8.86572734387776\n",
      "epoch=0, loss=8.771465461834024\n",
      "epoch=0, loss=9.158112328643504\n",
      "epoch=0, loss=9.08713012402755\n",
      "epoch=0, loss=9.12162626078487\n",
      "epoch=0, loss=9.126297164417627\n",
      "epoch=0, loss=9.067674164613972\n",
      "epoch=0, loss=9.198025179649688\n",
      "epoch=0, loss=9.250917529244326\n",
      "epoch=0, loss=8.885249082461067\n",
      "epoch=0, loss=9.319127356889032\n",
      "epoch=0, loss=8.64517982683666\n",
      "epoch=0, loss=8.78849570845141\n",
      "epoch=0, loss=9.650862774240863\n",
      "epoch=0, loss=8.824014242080853\n",
      "epoch=0, loss=8.289461896500963\n",
      "epoch=0, loss=9.311981544888415\n",
      "epoch=0, loss=9.264253719035679\n",
      "epoch=0, loss=8.77327684664234\n",
      "epoch=0, loss=8.87935052678862\n",
      "epoch=0, loss=9.319057583963287\n",
      "epoch=0, loss=8.414645709602786\n",
      "epoch=0, loss=9.451780870822443\n",
      "epoch=0, loss=8.803118109660307\n",
      "epoch=0, loss=8.68882459327652\n",
      "epoch=0, loss=8.54854542304039\n",
      "epoch=0, loss=8.894232344106463\n",
      "epoch=0, loss=8.946168498117679\n",
      "epoch=0, loss=9.210701784282081\n",
      "epoch=0, loss=8.764604397370842\n",
      "epoch=0, loss=8.726477235758175\n",
      "epoch=0, loss=9.074687825024895\n",
      "epoch=0, loss=8.931227285920132\n",
      "epoch=0, loss=9.163598091638175\n",
      "epoch=0, loss=8.927401567878142\n",
      "epoch=0, loss=9.254975149043299\n",
      "epoch=0, loss=9.126232214506711\n",
      "epoch=0, loss=8.825532659499205\n",
      "epoch=0, loss=9.32363319175023\n",
      "epoch=0, loss=8.992054231894812\n",
      "epoch=0, loss=8.89556840753267\n",
      "epoch=0, loss=9.164112008821041\n",
      "epoch=0, loss=9.20948147134982\n",
      "epoch=0, loss=8.824935793776453\n",
      "epoch=0, loss=8.76689089284547\n",
      "epoch=0, loss=8.98204718116643\n",
      "epoch=0, loss=8.964639917885178\n",
      "epoch=0, loss=8.782941530800178\n",
      "epoch=0, loss=9.122852333431878\n",
      "epoch=0, loss=8.885272058447327\n",
      "epoch=0, loss=9.009115791294066\n",
      "epoch=0, loss=8.535932033591745\n",
      "epoch=0, loss=9.005526298327796\n",
      "epoch=0, loss=9.26179231361122\n",
      "epoch=0, loss=8.795170461947903\n",
      "epoch=0, loss=8.96106615899265\n",
      "epoch=0, loss=8.579154531767518\n",
      "epoch=0, loss=9.017760551023649\n",
      "epoch=0, loss=8.807146695506635\n",
      "epoch=0, loss=8.623945478118237\n",
      "epoch=0, loss=9.08673245086818\n",
      "epoch=0, loss=8.716016115538274\n",
      "epoch=0, loss=8.907741694689681\n",
      "epoch=0, loss=8.421490125720476\n",
      "epoch=0, loss=8.831997182521672\n",
      "epoch=0, loss=8.755132543012124\n",
      "epoch=0, loss=8.639079766560144\n",
      "epoch=0, loss=8.887850489911168\n",
      "epoch=0, loss=8.960619321340085\n",
      "epoch=0, loss=9.551938945351617\n",
      "epoch=0, loss=8.790265005580112\n",
      "epoch=0, loss=9.002968493901118\n",
      "epoch=0, loss=8.28491832439184\n",
      "epoch=0, loss=8.782505863618827\n",
      "epoch=0, loss=9.4228399250498\n",
      "epoch=0, loss=8.803549348338665\n",
      "epoch=0, loss=8.991172300805145\n",
      "epoch=0, loss=8.909123780430638\n",
      "epoch=0, loss=8.984645501651595\n",
      "epoch=0, loss=9.816120040268375\n",
      "epoch=0, loss=8.772461833880959\n",
      "epoch=0, loss=9.23912903945545\n",
      "epoch=0, loss=9.648961697176667\n",
      "epoch=0, loss=9.545419939761759\n",
      "epoch=0, loss=9.042855132683531\n",
      "epoch=0, loss=8.792345413538648\n",
      "epoch=0, loss=8.71534421775228\n",
      "epoch=0, loss=9.000457680132707\n",
      "epoch=0, loss=9.256906888945307\n",
      "epoch=0, loss=9.427452736622197\n",
      "epoch=0, loss=8.87091841057189\n",
      "epoch=0, loss=9.021320711013551\n",
      "epoch=0, loss=8.531023537253127\n",
      "epoch=0, loss=9.17463108479487\n",
      "epoch=0, loss=8.823683215516859\n",
      "epoch=0, loss=9.423097565672741\n",
      "epoch=0, loss=8.649649796470742\n",
      "epoch=0, loss=8.839982528044526\n",
      "epoch=0, loss=9.05335985179653\n",
      "epoch=0, loss=9.150915327116328\n",
      "epoch=0, loss=9.030729776437871\n",
      "epoch=0, loss=9.19587338929106\n",
      "epoch=0, loss=9.45717373999539\n",
      "epoch=0, loss=9.054234010745018\n",
      "epoch=0, loss=9.353764249221124\n",
      "epoch=0, loss=9.10294195263442\n",
      "epoch=0, loss=8.584603146071295\n",
      "epoch=0, loss=8.280282988446812\n",
      "epoch=0, loss=9.410245923779332\n",
      "epoch=0, loss=8.695882455859422\n",
      "epoch=0, loss=8.492448463722404\n",
      "epoch=0, loss=8.933666455630691\n",
      "epoch=0, loss=8.729140047763353\n",
      "epoch=0, loss=8.186932881765786\n",
      "epoch=0, loss=9.09633846860482\n",
      "epoch=0, loss=9.788114711806806\n",
      "epoch=0, loss=9.123324185058712\n",
      "epoch=0, loss=8.875740232114552\n",
      "epoch=0, loss=8.844108797692684\n",
      "epoch=0, loss=9.075255136222793\n",
      "epoch=0, loss=8.481865260300868\n",
      "epoch=0, loss=8.637463399580014\n",
      "epoch=0, loss=9.293535617795277\n",
      "epoch=0, loss=8.409079056230325\n",
      "epoch=0, loss=8.963653043795633\n",
      "epoch=0, loss=8.714927081507513\n",
      "epoch=0, loss=8.73876564678997\n",
      "epoch=0, loss=8.86560778251389\n",
      "epoch=0, loss=9.065614161042797\n",
      "epoch=0, loss=8.837567189066029\n",
      "epoch=0, loss=9.105694494740908\n",
      "epoch=0, loss=8.799080407899226\n",
      "epoch=0, loss=8.741838891011396\n",
      "epoch=0, loss=8.792615484241251\n",
      "epoch=0, loss=8.612414861619623\n",
      "epoch=0, loss=8.766562625859414\n",
      "epoch=0, loss=8.372797794838311\n",
      "epoch=0, loss=9.151603664273063\n",
      "epoch=0, loss=9.031050370642\n",
      "epoch=0, loss=8.978032007283781\n",
      "epoch=0, loss=9.574018108153311\n",
      "epoch=0, loss=8.969053078887633\n",
      "epoch=0, loss=8.884114573047126\n",
      "epoch=0, loss=9.531325486775762\n",
      "epoch=0, loss=9.41600268427962\n",
      "epoch=0, loss=8.884790840633872\n",
      "epoch=0, loss=8.94647248384964\n",
      "epoch=0, loss=8.69738380166993\n",
      "epoch=0, loss=9.060447644039622\n",
      "epoch=0, loss=8.821815769228467\n",
      "epoch=0, loss=9.478139429650566\n",
      "epoch=0, loss=9.04718896408275\n",
      "epoch=0, loss=9.058772333625642\n",
      "epoch=0, loss=8.746953890984651\n",
      "epoch=0, loss=9.116230395200153\n",
      "epoch=0, loss=9.011865381840309\n",
      "epoch=0, loss=8.514141926127536\n",
      "epoch=0, loss=8.62058416405017\n",
      "epoch=0, loss=8.658655803566877\n",
      "epoch=0, loss=8.769110680338885\n",
      "epoch=0, loss=8.558629101371052\n",
      "epoch=0, loss=8.793676271786074\n",
      "epoch=0, loss=8.925951164096004\n",
      "epoch=0, loss=8.631277161664274\n",
      "epoch=0, loss=8.515374260435266\n",
      "epoch=0, loss=9.03997869915828\n",
      "epoch=0, loss=8.492254025007574\n",
      "epoch=0, loss=8.676725944083808\n",
      "epoch=0, loss=8.52869378835257\n",
      "epoch=0, loss=9.009383973502283\n",
      "epoch=0, loss=9.374712829587445\n",
      "epoch=0, loss=8.894212188424925\n",
      "epoch=0, loss=8.003923991076807\n",
      "epoch=0, loss=8.729903074051439\n",
      "epoch=0, loss=8.770563335048157\n",
      "epoch=0, loss=9.942870603310725\n",
      "epoch=0, loss=8.913363587599273\n",
      "epoch=0, loss=8.546301927290058\n",
      "epoch=0, loss=8.806424295693066\n",
      "epoch=0, loss=8.832471439767563\n",
      "epoch=0, loss=8.823182128081587\n",
      "epoch=0, loss=8.836467951490176\n",
      "epoch=0, loss=9.275918598912245\n",
      "epoch=0, loss=8.821900602577385\n",
      "epoch=0, loss=8.591325282755912\n",
      "epoch=0, loss=8.033857777794056\n",
      "epoch=0, loss=8.50011112568025\n",
      "epoch=0, loss=8.881395444450874\n",
      "epoch=0, loss=8.490446722549322\n",
      "epoch=0, loss=8.553101158924282\n",
      "epoch=0, loss=8.334011941610921\n",
      "epoch=0, loss=8.972964452724122\n",
      "epoch=0, loss=8.637074528182874\n",
      "epoch=0, loss=8.679335985509313\n",
      "epoch=0, loss=8.722729412539481\n",
      "epoch=0, loss=9.126980519038364\n",
      "epoch=0, loss=8.752469155450703\n",
      "epoch=0, loss=8.380380222463147\n",
      "epoch=0, loss=8.933365560790321\n",
      "epoch=0, loss=8.758003315338769\n",
      "epoch=0, loss=8.496869288515436\n",
      "epoch=0, loss=8.51690178883021\n",
      "epoch=0, loss=9.013535494940367\n",
      "epoch=0, loss=8.512002240173038\n",
      "epoch=0, loss=8.492877969927475\n",
      "epoch=0, loss=8.725353205478195\n",
      "epoch=0, loss=8.811392981797797\n",
      "epoch=0, loss=8.91185136905717\n",
      "epoch=0, loss=8.258811140747747\n",
      "epoch=0, loss=7.6535429467469305\n",
      "epoch=0, loss=8.929112954444042\n",
      "epoch=0, loss=8.189377448128463\n",
      "epoch=0, loss=8.28240418332793\n",
      "epoch=0, loss=9.135967183653683\n",
      "epoch=0, loss=8.477202032992137\n",
      "epoch=0, loss=9.492055229676271\n",
      "epoch=0, loss=8.773162132341016\n",
      "epoch=0, loss=8.242282498589846\n",
      "epoch=0, loss=9.377637753932598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, loss=8.807200752932044\n",
      "epoch=0, loss=8.326778923458289\n",
      "epoch=0, loss=7.8821734846577\n",
      "epoch=0, loss=9.037437267014479\n",
      "epoch=0, loss=10.160206554924393\n",
      "epoch=0, loss=10.167562716929604\n",
      "epoch=0, loss=10.079208864515627\n",
      "epoch=0, loss=9.343975270966027\n",
      "epoch=0, loss=9.714053500083\n",
      "epoch=0, loss=8.881630632425633\n",
      "epoch=0, loss=8.442906677164379\n",
      "epoch=0, loss=8.157797349450043\n",
      "epoch=0, loss=9.887356227736388\n",
      "epoch=0, loss=9.660810169265453\n",
      "epoch=0, loss=9.568223163549469\n",
      "epoch=0, loss=9.615294997878\n",
      "epoch=0, loss=9.57397833467119\n",
      "epoch=0, loss=9.282134188854107\n",
      "epoch=0, loss=8.002554330984076\n",
      "epoch=0, loss=8.029509266849983\n",
      "epoch=0, loss=8.453221188545974\n",
      "epoch=0, loss=8.09752160741502\n",
      "epoch=0, loss=8.797901079382568\n",
      "epoch=0, loss=8.65464773218109\n",
      "epoch=0, loss=8.92904027426414\n",
      "epoch=0, loss=8.440700937365772\n",
      "epoch=0, loss=9.37044062641311\n",
      "epoch=0, loss=9.330128810289507\n",
      "epoch=0, loss=9.298548853826391\n",
      "epoch=0, loss=8.419613590325508\n",
      "epoch=0, loss=8.70853222273542\n",
      "epoch=0, loss=8.354324030533274\n",
      "epoch=0, loss=8.840638517188795\n",
      "epoch=0, loss=9.20276086023604\n",
      "epoch=0, loss=8.854408514790512\n",
      "epoch=0, loss=8.334997635423134\n",
      "epoch=0, loss=8.822521767365787\n",
      "epoch=0, loss=8.942904203792988\n",
      "epoch=0, loss=8.78047590710532\n",
      "epoch=0, loss=9.176649361969968\n",
      "epoch=0, loss=8.498636233447375\n",
      "epoch=0, loss=9.140625475427898\n",
      "epoch=0, loss=8.682325478495088\n",
      "epoch=0, loss=9.050552989036035\n",
      "epoch=0, loss=8.386282961402774\n",
      "epoch=0, loss=9.182882970816923\n",
      "epoch=0, loss=8.3768752183293\n",
      "epoch=0, loss=8.077370298115502\n",
      "epoch=0, loss=8.902396827625967\n",
      "epoch=0, loss=8.351270030849308\n",
      "epoch=0, loss=8.897217025310994\n",
      "epoch=0, loss=8.722886047958111\n",
      "epoch=0, loss=8.990103931335604\n",
      "epoch=0, loss=8.66023585726944\n",
      "epoch=0, loss=8.73667363395592\n",
      "epoch=0, loss=7.852725536862873\n",
      "epoch=0, loss=8.56673627611844\n",
      "epoch=0, loss=8.882752941387844\n",
      "epoch=0, loss=8.460506281275165\n",
      "epoch=0, loss=7.980581737825364\n",
      "epoch=0, loss=8.371919239853018\n",
      "epoch=0, loss=8.090683991457338\n",
      "epoch=0, loss=7.700907317234671\n",
      "epoch=0, loss=7.792439034084852\n",
      "epoch=0, loss=8.467252753651882\n",
      "epoch=0, loss=8.645975306444612\n",
      "epoch=0, loss=8.26287897177059\n",
      "epoch=0, loss=8.415350140452817\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-35347ae38541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerate_batch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# predictions = model.predict(X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-6ac6ee2e0d7b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, epochs, learning_rate)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-6ac6ee2e0d7b>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_out\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "vocab_size = len(vocab)\n",
    "embedding_size = 10\n",
    "model.add(Linear(vocab_size, embedding_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Linear(embedding_size, vocab_size))\n",
    "\n",
    "model.set_loss(CrossEntropyLoss)\n",
    "\n",
    "for X, y in generate_batch_data(tokens, vocab):\n",
    "    model.train(X, y, epochs=1, learning_rate=0.1)\n",
    "\n",
    "# predictions = model.predict(X)\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(generate_batch_data(tokens, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, loss=10.728138439199919\n",
      "epoch=1, loss=10.722454452383854\n",
      "epoch=2, loss=10.716771774968786\n",
      "epoch=3, loss=10.711090398949281\n",
      "epoch=4, loss=10.705410316345377\n",
      "epoch=5, loss=10.699731519203311\n",
      "epoch=6, loss=10.694053999595774\n",
      "epoch=7, loss=10.688377749622466\n",
      "epoch=8, loss=10.682702761410516\n",
      "epoch=9, loss=10.677029027115044\n",
      "epoch=10, loss=10.671356538919705\n",
      "epoch=11, loss=10.665685289037045\n",
      "epoch=12, loss=10.660015269709247\n",
      "epoch=13, loss=10.65434647320847\n",
      "epoch=14, loss=10.648678891837534\n",
      "epoch=15, loss=10.643012517930464\n",
      "epoch=16, loss=10.637347343853063\n",
      "epoch=17, loss=10.631683362003487\n",
      "epoch=18, loss=10.62602056481293\n",
      "epoch=19, loss=10.620358944746085\n",
      "epoch=20, loss=10.61469849430205\n",
      "epoch=21, loss=10.609039206014664\n",
      "epoch=22, loss=10.603381072453507\n",
      "epoch=23, loss=10.597724086224313\n",
      "epoch=24, loss=10.592068239969779\n",
      "epoch=25, loss=10.586413526370379\n",
      "epoch=26, loss=10.580759938144906\n",
      "epoch=27, loss=10.575107468051435\n",
      "epoch=28, loss=10.569456108887872\n",
      "epoch=29, loss=10.56380585349294\n",
      "epoch=30, loss=10.558156694746922\n",
      "epoch=31, loss=10.552508625572392\n",
      "epoch=32, loss=10.546861638935244\n",
      "epoch=33, loss=10.54121572784541\n",
      "epoch=34, loss=10.53557088535787\n",
      "epoch=35, loss=10.529927104573353\n",
      "epoch=36, loss=10.524284378639566\n",
      "epoch=37, loss=10.518642700751897\n",
      "epoch=38, loss=10.513002064154568\n",
      "epoch=39, loss=10.507362462141451\n",
      "epoch=40, loss=10.501723888057304\n",
      "epoch=41, loss=10.496086335298605\n",
      "epoch=42, loss=10.4904497973148\n",
      "epoch=43, loss=10.484814267609343\n",
      "epoch=44, loss=10.47917973974076\n",
      "epoch=45, loss=10.473546207323851\n",
      "epoch=46, loss=10.46791366403094\n",
      "epoch=47, loss=10.462282103592926\n",
      "epoch=48, loss=10.456651519800658\n",
      "epoch=49, loss=10.45102190650615\n",
      "epoch=50, loss=10.445393257623786\n",
      "epoch=51, loss=10.439765567131916\n",
      "epoch=52, loss=10.434138829073834\n",
      "epoch=53, loss=10.428513037559561\n",
      "epoch=54, loss=10.422888186766917\n",
      "epoch=55, loss=10.417264270943274\n",
      "epoch=56, loss=10.411641284406812\n",
      "epoch=57, loss=10.406019221548275\n",
      "epoch=58, loss=10.400398076832323\n",
      "epoch=59, loss=10.394777844799249\n",
      "epoch=60, loss=10.389158520066676\n",
      "epoch=61, loss=10.383540097331137\n",
      "epoch=62, loss=10.377922571369755\n",
      "epoch=63, loss=10.372305937042235\n",
      "epoch=64, loss=10.366690189292388\n",
      "epoch=65, loss=10.361075323150171\n",
      "epoch=66, loss=10.355461333733547\n",
      "epoch=67, loss=10.349848216250361\n",
      "epoch=68, loss=10.344235966000372\n",
      "epoch=69, loss=10.33862457837732\n",
      "epoch=70, loss=10.33301404887097\n",
      "epoch=71, loss=10.327404373069168\n",
      "epoch=72, loss=10.32179554666026\n",
      "epoch=73, loss=10.316187565435065\n",
      "epoch=74, loss=10.310580425289285\n",
      "epoch=75, loss=10.304974122225918\n",
      "epoch=76, loss=10.299368652357527\n",
      "epoch=77, loss=10.293764011908827\n",
      "epoch=78, loss=10.288160197219067\n",
      "epoch=79, loss=10.282557204744759\n",
      "epoch=80, loss=10.27695503106222\n",
      "epoch=81, loss=10.271353672870287\n",
      "epoch=82, loss=10.265753126993179\n",
      "epoch=83, loss=10.260153390383193\n",
      "epoch=84, loss=10.254554460123776\n",
      "epoch=85, loss=10.248956333432368\n",
      "epoch=86, loss=10.243359007663457\n",
      "epoch=87, loss=10.237762480311815\n",
      "epoch=88, loss=10.232166749015567\n",
      "epoch=89, loss=10.226571811559609\n",
      "epoch=90, loss=10.22097766587875\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "vocab_size = len(vocab)\n",
    "embedding_size = 10\n",
    "model.add(Linear(vocab_size, embedding_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Linear(embedding_size, vocab_size))\n",
    "\n",
    "model.set_loss(CrossEntropyLoss)\n",
    "X, y = generate_train_data(tokens[:1000], vocab)\n",
    "model.train(X, y, epochs=100, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
